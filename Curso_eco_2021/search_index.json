[["apresentação.html", "ESTUDOS ECOLÓGICOS 2021 1 Apresentação", " ESTUDOS ECOLÓGICOS 2021 Oswaldo G Cruz &amp; Laís P Freitas Atualizado em: 28 de maio de 2021 1 Apresentação Disciplina: Estudos Ecológicos - Introdução aos Métodos de Análises Temporais e Espaciais (ENSP.82.134.2) Carga Horaria: 90 horas (10 aulas) - 3 Créditos Professores: Oswaldo G Cruz &amp; Laís P Freitas Período: 07 de Maio de 2021 a 09 de Julho 2021 Ementa: Este curso se propõe a estudar métodos de séries temporais e estatística espacial, visando analisar a saúde de grupos populacionais a partir de sua localização temporal e espacial, bem como sua interação com o ambiente. Serão abordados os seguintes tópicos: Introdução e definições de estudos ecológicos; falácia ecológica vs falácia atomista; introdução, definições e importância das sereis temporais; tendência e sazonalidade; autocorrelação serial; filtros e alisamentos; modelo Box &amp; Jenkings (ARIMA); Tipologia dos dados espaciais; Padrão de pontos; Área; Geoestatística. Modelos aditivos generalizados (GAM). O curso terá aulas práticas realizadas em R. Cronograma Aula 1 (07/05) - Estudos Ecológicos Aula 2 (14/05) - Séries Temporais - Análise Exploratória Aula 3 (21/05) - Séries Temporais - Técnicas de Suavização Aula 4 (28/05) - Modelagem em Séries Temporais Aula 5 (04/06) - Introdução à Análise Estatística Espacial &amp; Padrão de Pontos I Aula 6 (11/06) - Análise Espacial - Padrão de Pontos II Aula 7 (18/06) - Análise Espacial - Dados de Área I Aula 8 (25/06) - Análise Espacial - Dados de Área II Aula 9 (02/07) - Análise Espacial - Geoestatística Aula 10 (09/07) - Análise Espaço-Temporal &amp; Instruções e Dúvidas para o Trabalho Final Monitor: Denis de Oliveira Rodrigues Avaliação: Instruções para o Trabalho Final Prazo final: 06/08/2021 Clique AQUI para instruções "],["estudos-ecológicos.html", " 2 Estudos Ecológicos 2.1 O que são Estudos Ecológicos ? 2.2 Principais objetivos 2.3 Tipos de Variáveis Utilizadas 2.4 Tipos de Desenhos de Estudos Ecológicos 2.5 Aspectos históricos 2.6 Epidemiologia social 2.7 Árvores, Bosques ou as Florestas? 2.8 Falácia Ecológica ou viés de agregação 2.9 Problemas práticos 2.10 Vantagens 2.11 Desvantagens 2.12 Resumindo 2.13 Exercícios Propostos 2.14 Bibliografia sugerida", " 2 Estudos Ecológicos 2.1 O que são Estudos Ecológicos ? São estudos nos quais a unidade de análise (ou agregação) é uma população ou um grupo de pessoas, geralmente de uma área geográfica definida (ex: um país, um estado, uma cidade, etc.), em um determinado tempo definido. Definição Clássica: é um estudo observacional com a informação obtida e analisada no nível agregado. Geralmente são mais baratos e mais rápidos do que estudos envolvendo o indivíduo como unidade de análise. Procuram avaliar como os contextos (sociais, ambientais, etc) podem afetar a saúde de grupos populacionais. 2.2 Principais objetivos Gerar hipóteses etiológicas; Testar hipóteses etiológicas; Avaliar a efetividade de intervenções na população; Identificar áreas de risco. Exemplo 1: Em 1960, Friedman mostrou uma correlação positiva entre as taxas de mortalidade por doença coronariana (DC) e as vendas de cigarros per capita, em 44 estados americanos. Esta observação inicial contribuiu para a formulação da hipótese de que o tabagismo poderia causar doença coronariana Figura: Coronary heart disease mortality rates in the United States per capita cigarette sales in 1960, by state. (From FRIEDMAN GD, Cigarette smoking and geographic variation in coronary heart disease mortality in the United States. J. Chronic Dis. 20: 769, 1967) 2.3 Tipos de Variáveis Utilizadas Medidas Agregadas: Medidas agregadas por grupos. ex: incidência, prevalência, mortalidade, proporção de fumantes; Medidas Ambientais: Características físicas do contexto onde o grupo convive. ex: nível de poluição, precipitação; Medidas Globais: Atributos de grupos, organizações ou lugares, que não podem ser mensurados a nível individual. ex: IDH, densidade demográfica, existência de um tipo de sistema de saúde. Em uma análise ecológica, todas as variáveis são medidas agrupadas. Apenas se conhece a distribuição marginal de cada variável. Desfecho (Y) Fator em Estudo (X) Ocorreu Não ocorreu Total Exposto ? ? \\(E_1\\) Não Exposto ? ? \\(E_0\\) Total \\(D_1\\) \\(D_0\\) n 2.4 Tipos de Desenhos de Estudos Ecológicos Múltiplos Grupos: O objetivo desse tipo de estudo é a comparação entre todos os grupos ou conjuntos populacionais envolvidos no estudo. Ex: Análise Espacial. Desenhos de Séries Temporais: Avalia um determinado desfecho ao longo do tempo em uma determinada população geograficamente definida. Ex: Análise de Séries Temporais. Desenhos Mistos: É a combinação entre os dois desenhos citados, pois avalia a evolução de um determinado desfecho em diferentes grupos populacionais ao longo do tempo. Ex: Análise Espaço-Temporais, Estudos Multiníveis. 2.5 Aspectos históricos “Um estudo ecológico ou agregado focaliza a comparação de grupos, ao invés de indivíduos. A razão subjacente para este foco é que dados a nível individual da distribuição conjunta de duas (ou talvez todas) variáveis estão faltando internamente nos grupos; neste sentido um estudo ecológico é um desenho incompleto”. (Rothman, Kenneth J. et al. Modern epidemiology. Philadelphia: Wolters Kluwer Health/Lippincott Williams &amp; Wilkins, 2008.) “… estudar saúde no contexto ambiental. O objetivo é ambicioso: entender como o contexto afeta a saúde de pessoas e grupo através de seleção, distribuição, interação, adaptação, e outras respostas. Medidas de atributos do indivíduo não podem dar conta destes processos […] Sem medir estes contextos, nem padrão de mortalidade e morbidade, nem o espalhamento epidêmico, nem a transmissão sexual podem ser explicados” (Susser, Am.J.Public Health, 1994;84:825-835) A Epidemiologia é frequentemente definida em termos do estudo da determinação da distribuição da doença. Mas não se deve esquecer que quanto mais espalhada é uma causa particular, menos ela contribui para explicar a distribuição da doença.” “…dois tipos de perguntas etiológicas. A primeira busca as causas dos casos, e a segunda as causas da incidência.” “Aplicada à etiologia, a visão centralizada no indivíduo leva ao uso do risco-relativo como a representação básica da força etiológica: ou seja, o risco em indivíduos expostos relativo aos não-expostos. […] Esta pode ser geralmente a melhor medida de força etiológica, mas não é medida de […] importância em saúde pública.” “É rara a doença cuja taxa de incidência não tenha variado largamente, seja ao longo do tempo ou entre populações […] Isto significa que as causas da incidência, desconhecidas que sejam, não são inevitáveis. […] Mas identificar o agente causal pelos métodos tradicionais de caso-controle e coorte não terá sucesso se não houver suficientes diferenças na exposição dentro da população […] Nestas circunstâncias tudo os que os métodos tradicionais fazem é encontrar marcadores de susceptibilidade individual. A chave deve ser buscada nas diferenças entre populações ou em mudanças nas populações ao longo do tempo.” (Rose G. Sick individuals and sick populations. Int J Epidemiol. 2001 Jun;30(3):427-32; discussion 433-4.) “ … torna-se aparente que muitas das explicações convencionais dos determinantes da saúde - porque algumas pessoas são saudáveis e outras não - são, na melhor das hipóteses seriamente incompletas, se não simplesmente erradas. É assim, infelizmente, porque as sociedades modernas dedicam uma parte muito grande de sua riqueza, esforço e atenção tentando manter ou melhorar a saúde dos indivíduos que compõem suas populações. Estes esforços maciços são primeiramente canalizados para os sistemas de assistência à saúde, presumivelmente refletindo uma crença que receber uma boa assistência é o mais importante determinante de saúde.” (Evans,R.G.”Why are some people healthy and others not”) “Grande parte da pesquisa atual em epidemiologia está baseada no individualismo metodológico: a noção que a distribuição da saúde e doença em populações pode ser explicada exclusivamente em termos das características dos indivíduos.” (Diez-Roux AV. Bringing context back into epidemiology: variables and fallacies in multilevel analysis. AJPH,1998;88(2):216-22) “A evidência de modestos efeitos de vizinhança na saúde é razoavelmente consistente, apesar da heterogeneidade dos desenhos dos estudos […] e prováveis erros de medida. Ao chamar a atenção da saúde pública para os riscos associados com a estrutura social e ecológica de vizinhança, enseja-se possíveis intervenções inovadoras no nível da comunidade.” (Pickett KE, PearlL M. Multilevel analyses of neighbourhood socioeconomic context and health outcomes: a critical review. J Epidemiol Community Health 2001;55(2):111-22) 2.6 Epidemiologia social “…o ramo da epidemiologia que estuda a distribuição social e os determinantes sociais da saúde. A epidemiologia social incorpora um novo foco na comunidade como uma entidade em si, uma entidade mais complexa do que a soma das pessoas individuais que compõem a sociedade.” (Berkman L. F. &amp; Kawachi I. (Editors). Social Epidemiology. Oxford University Press, 2000) “Os médicos estão acostumados a pensar nos determinantes socioeconômicos da doença em termos dos fatores de risco de uma pessoa. […] Agora parece claro que a riqueza absoluta ou a renda é um determinante menos importante da saúde do que a relativa disparidade na renda ou a diferença de renda entre os ricos e os pobres.” (Kawachi I.; Kennedy B.P.; Wilkinson R.G. The Society and Population Health Reader: Income Inequality and Health. New Press, 1999). 2.7 Árvores, Bosques ou as Florestas? 2.7.1 As Árvores Suponha os dados abaixo, onde a variável “X” representa um efeito de exposição e a variável “Y” um taxa. Ao fazermos uma regressão obtemos uma correlação de apenas 0,1469 entre as duas variáveis. 2.7.2 Os Bosques Ao estratificarmos os dados evidencia-se uma estrutura, e ajustarmos uma regressão em cada grupo obtém-se: 2.7.3 As Florestas Tirando-se a média para cada grupo iremos obter quatro pontos sob os quais faremos uma regressão. O coeficiente de correlação obtido é rho = 0,9938 2.8 Falácia Ecológica ou viés de agregação “Viés que pode ocorrer porque uma associação entre duas variáveis no nível agregado não necessariamente representa uma associação no nível individual” O problema é que não podemos fazer inferências para níveis distintos: Inferir para o indivíduos a partir de dados agregados (falácia ecológica) Inferir para agregados populacionais a partir de dados individuais (falácia atomística ou individualista) Na estatística esse efeito é conhecido como Paradoxo de Simpson “Textos de Epidemiologia fazem uma avaliação consistente sobre estudos ecológicos: eles são tentativas cruas de estimar correlações em nível individual. […] Examinar esta questão de uma perspectiva diferente - como um problema geral de validade - mostrará que a falácia ecológica, conforme frequentemente usada, encoraja três noções interrelacionadas e falaciosas: que modelos em nível individual são mais perfeitamente especificados que os de nível ecológico, que correlações ecológicas são sempre substitutos para correlações de nível individual, e que variáveis de nível de grupo não causam doença.” (Schwartz, Am.J.Public Health, 1994;84:819-824) Religião e Sucídio Um exemplo clássico de estudo ecológico: Emile Durkheim (em 1897) associação ecológica positiva entre a proporção de indivíduos de religião Protestante e as taxas de suicídio (províncias da Prússia); Durkheim concluiu que Protestantes tinham maior probabilidade de se suicidarem do que os Católicos; Conclusão factível mas a inferência causal não é correta: poderiam ter sido os Católicos em províncias predominantemente Protestantes a cometer os suicídios, e a metodologia ecológica não permite discernir qual das duas hipóteses está certa. Para ler mais sobre este exemplo: Frans van Poppel and Lincoln H. Day. A Test of Durkheim’s Theory of Suicide - Without Committing the “Ecological Fallacy”. American Sociological Review, 1996. https://doi.org/10.2307/2096361 Posse de armas de fogo e suicídio Um exemplo mais recente: Miller et al (2003) realizaram um estudo ecológico no Estados Unidos comparando as frequências de posse doméstica de armas de fogo com as de suicídio por arma de fogo e por outros meios, por estado. Estados com maiores proporções de posse de armas de fogo apresentaram maiores taxas de suicídio por armas de fogo, mas a mesma frequência de suicídios por outros meios. Suicídios por outros meios serve como um “controle”. Segundo os autores, a posse de armas não deveria impactar suicídios por outros meios. Além disso, os autores assumem que os fatores de confundimento seriam os mesmos para suicídios por arma de fogo e por outros meios. Figura. Relação entre posse doméstica de armas de fogo e mortalidade por suicídio nos Estados Unidos, por estado, A) por armas de fogo, B) por outros meios que não armas de fogo, e C) todos. (Fonte: Miller et al. Am J Epidemiol. 2013;178(6):946–955) Concordam que todos os confundimentos são os mesmos para os dois grupos de mortes por suicídio? Concordam que suicídios por outros meios não devem ser afetados pela posse doméstica de armas de fogo? É correto concluir que, nos Estados Unidos: ter uma maior porcentagem de população com posse de armas causa taxas elevadas de suicídio por arma de fogo? possuir uma arma é uma causa para suicídio por arma de fogo? Um outro exemplo: Um pesquisador deseja estudar a relação entre acidentes de trânsito e a renda em três cidade distintas (A, B e C). pop renda_media tx_acidente A 24.08571 57.14 B 22.57143 42.86 C 21.41429 28.57 Observando o gráfico abaixo, o pesquisador observa um possível associaçãom entre a renda e a taxa de acidentes de trânsito; Quanto maior a renda, maior será a taxa de acidentes de trânsito. Observando os microdados, ou seja, os dados no nível individual, temos o seguinte: De posse desses dados no nível individual, é possível fazer a seguinte análise: Dessa forma observamos que os indivíduos que sofreram algum tipo de acidente de trânsito, apresentam a menor renda; Qual dos dois níveis de inferência está errado ? Qual é, então, o problema ? ? ? 2.9 Problemas práticos 1. Numerador: subregistro duplicidade de registros georreferenciamento: não localização informação incorreta preenchimento inadequado mudança na classificação ao longo do tempo 2. Denominador: espaçamento do censo migração mudança de fronteiras (!!!!) 3.Exposição: pode ocorrer em diversos lugares dificilmente mensurável com precisão uso de “proxy” diferentes áreas para medida de exposição e de efeito, e áreas não compatíveis Informações mais detalhadas (PNAD, amostra do censo) não extrapoláveis para populações pequenas 4. Análise: migração multicolinearidade 2.10 Vantagens Baixo custo e execução rápida, devido às fontes de dados secundários disponíveis; Conseguem estimar bem os efeitos de uma exposição quando ela varia pouco na área de estudo, pela comparação entre áreas (os estudos individuais não conseguem); Existem efeitos que somente podem ser medidos no nível ecológico, por ex. implantação de um novo sistema de saúde. 2.11 Desvantagens Informações sobre comportamento, atitudes e história clínica não estão disponíveis (dados pessoais não disponíveis); Depende da qualidade das informações disponíveis (fontes diversas); Não se leva em conta a variabilidade da característica estudada dentro do grupo; Difícil estabelecer temporalidade entre causa e efeito. Migração entre grupos (por exemplo, mora em uma área e trabalha em outra). 2.12 Resumindo Resgatando a ecologia: estudo das complexas inter-relações entre organismos vivos e o seu meio físico. Dados agregados – estudo ecológico clássico Mistura de dados individuais e agregados – modelos multinível Quando se estuda o tempo – séries temporais e modelos dinâmicos Quando é espacial – modelos clássicos de regressão ou espaciais Mistura espaço e tempo – modelos espaço-temporais Envolvendo relações entre indivíduos – redes 2.13 Exercícios Propostos As estatísticas internacionais indicam que o Chile tem uma das mais altas taxas de mortalidade por câncer de estômago. O país caracteriza-se por conter altos níveis de nitrato em seu solo, situação rara no mundo, neste particular. Estabeleceu-se a suspeita de ser o nitrato, em altas concentrações, um agente causal da neoplasia. Comparações regionais dentro do país, contrastando áreas com altas e baixas concentrações de nitrato, mostraram a mesma relação: alto teor da substância no solo, (alta mortalidade por este tipo de neoplasia). Um estudo caso-controle subseqüente foi realizado, mas a nível individual, não foi possível encontrar tal associação. A hipótese, entretanto, não foi totalmente descartada. Qual a importância desse estudo ecológico no estudo sobre causalidade: concentração de nitrato no solo vs câncer de estômago ? Os casos notificados de Influenza são maiores na cidade A do que na cidade B. As taxas de vacinação para a influenza são mais baixas na cidade A do que na cidade B. Quais das seguintes razões são razões pelas quais seria é incorreto presumir que uma maior vacinação na cidade B é o que está fazendo com que a cidade B tenha menos casos relatados de Influenza ? Escolha as opções corretas. A cidade A e a cidade B podem ter diferentes cepas de Influenza A cidade A e a cidade B podem ter proporções diferentes de pessoas nas suas populações que são especialmente vulneráveis à influenza (por exemplo, idosos, crianças e mulheres grávidas) A cidade A e a cidade B podem ter diferenças nos cuidados de saúde , acessibilidade aos serviços e acesso a diagnóstico da influenza A cidade A e a cidade B podem ter climas diferentes, levando a diferenças em como/onde as pessoas entram em contato com um ao outro. Isto pode afetar as taxas de transmissão de Influenza 2.14 Bibliografia sugerida BERKMAN, Lisa F.; KAWACHI, Ichirō; GLYMOUR, M. Maria (Ed.). Social epidemiology. Oxford University Press, 2014. DIEZ-ROUX, Ana V. Bringing context back into epidemiology: variables and fallacies in multilevel analysis. American journal of public health, v. 88, n. 2, p. 216-222, 1998. EVANS, Robert G.; BARER, Morris L.; MARMOR, Theodore R. (Ed.). Why are some people healthy and others not?: The determinants of the health of populations. Transaction Publishers, 1994. MORGENSTERN, Hal. Ecologic studies in epidemiology: concepts, principles, and methods. Annual review of public health, v. 16, n. 1, p. 61-81, 1995. PICKETT, Kate E.; PEARL, Michelle. Multilevel analyses of neighbourhood socioeconomic context and health outcomes: a critical review. Journal of Epidemiology &amp; Community Health, v. 55, n. 2, p. 111-122, 2001. ROSE, Geoffrey. Sick individuals and sick populations. International journal of epidemiology, v. 30, n. 3, p. 427-432, 2001. "],["introdução-às-séries-temporais.html", " 3 Introdução às Séries Temporais 3.1 O que são Séries Temporais ? 3.2 Hipóteses básicas do estudo das séries temporais 3.3 Classificação dos tipos de séries temporais 3.4 Processo Estocástico 3.5 Notação e Nomenclatura 3.6 Objetivos: análise de séries temporais 3.7 Estacionariedade 3.8 Pressuposto da Independência 3.9 Dependência serial 3.10 Função de Autocorrelação - FAC (Autocorrelation function - ACF) 3.11 Componentes de uma Série Temporal 3.12 Tendência 3.13 Sazonalidade 3.14 Ciclo 3.15 Termo Aleatório ou Ruído Branco 3.16 Composição dos Modelos de séries temporais 3.17 Decomposição de séries temporais 3.18 Prática no R 3.19 Exercícios Propostos 3.20 Outros materiais sobre Séries Temporais 3.21 Bibliografia sugerida", " 3 Introdução às Séries Temporais 3.1 O que são Séries Temporais ? Definição: Entende-se por Séries Temporais (ST) todo e qualquer conjunto de dados (absolutos ou relativos, discretos ou contínuos), ordenados cronologicamente. Condição: Esses dados seguem uma ordenação em função do tempo (dependência temporal). De modo geral, as séries temporais apresentam sequências de observações relativas a determinada variável ao longo de um intervalo específico de tempo (dia, mês, trimestre, ano, etc.), isto é, referem-se a fluxos de valores periódicos, os quais dão uma visão geral sobre o andamento ou comportamento da variável em análise. A maneira mais comum de visualizar séries temporais é usar um gráfico de linhas simples, em que o eixo horizontal representa os incrementos de tempo e o eixo vertical representa a variável que está sendo medida. Seguem abaixo alguns exemplo de séries temporais: As séries temporais podem ser de natureza regular ou irregular. As séries temporais regulares ou uniformes são aquelas que podem ser expressas sempre com o mesmo intervalo de tempo (frequência). As séries temporais irregulares ou não uniformes são aquelas em que as frequências de tempo são diferentes ou que apresentam dados ausentes (missing data). Algumas vezes podem ser transformadas em séries regulares agregando ouinterpolando os dados mensurados. 3.2 Hipóteses básicas do estudo das séries temporais Há um sistema causal relacionando as variáveis no tempo; Ao longo do tempo, o sistema influencia todos os dados sob análise, de modo regular e permanente; Os dados históricos refletem a influência média de um conjunto de fatores. Tais hipóteses se baseiam no pressuposto de que as relações apontadas pela experiência pregressa permitem prever o possível comportamento das variáveis sob análise, determinando se seu comportamento apresenta propriedades determinísticas e/ou aleatórias. 3.3 Classificação dos tipos de séries temporais Contínuas: A informação é obtida em qualquer intervalo de tempo (podendo ser discretizando em intervalos iguais) ou é acumulada por período. Ex: Temperatura, pluviosidade, partículas em suspensão. Discretas: Observações obtidas em intervalos de tempo discreto e equidistantes (ano, mês, dias, semanas epidemiológicas). Ex: Mortalidade infantil, notificações por DIC. Multivariada: São várias coleções de observações para a mesma sequência de períodos de tempo, ou seja,envolvem mais de uma série histórica. Ex: Número de homicídios e acidentes no Sudeste. Multidimensional: São várias coleções de observações para a mesma sequência de períodos de tempo, descrevendo o mesmo fenômeno em diferentes contextos. Ex: Número de AVCs em diversas UFs. 3.4 Processo Estocástico Um processo estocástico pode ser pensado de duas formas: um conjunto de possíveis trajetórias de um fenômeno físico que poderiam ser observadas; um conjunto de variáveis aleatórias, uma para cada tempo \\(t\\). Cada valor observado de uma trajetória é um dos possíveis valores que poderiam ter sido observados, de acordo com a distribuição de probabilidades da respectiva variável aleatória. Definir séries temporais consiste em determinar as funções matemáticas que apontam suas componentes básicas e permitem prever a evolução dos fenômenos estudados (como um eventual crescimento ou decrescimento futuro). As séries temporais podem ser matematicamente representadas por funções do tipo: \\[Z_t = f(tempo, a)\\] Sendo \\(Z_t\\) o valor da variável \\(Z\\) no tempo \\(t\\), e \\(a\\) a componente aleatória associada à função matemática do tempo. Série com a mesma estrutura: cada série é uma possível realização do mesmo processo estocástico. Trajetória ou série temporal ou função amostral 3.5 Notação e Nomenclatura Matematicamente, uma série temporal discreta é representada por: \\(Z_t = (Z_1 , Z_2 , Z_3 , ... , Z_n)\\), sendo: \\(Z\\), a variável observável e \\(t = 1,2,...,n\\), o parâmetro do tempo. Simulando duas séries temporais de um evento, com a mesma estrutura: 3.6 Objetivos: análise de séries temporais Objetivo Exemplo Descrição: verificar existência de tendência, sazonalidade, ciclos. Histogramas, boxplots, são ferramentas da análise exploratória descritiva Identificar tendência da AIDS; sazonalidade da dengue visando estabelecer melhor período de intervenção. Estabelecimento de causalidade: estudo da relação de causa-efeito Vacina X sarampo; Mortalidade por DIC X melhor assistência Classificação: identificação de padrões A série de leishmaniose tegumentar é “igual” à visceral? Controle: sistemas dinâmicos, caracterizados por uma entrada \\(X_t\\), uma série de saída \\(Z_t\\) e uma função de transferência \\(V_t\\) Modelar a resposta a medidas de controle de epidemia Monitoramento (nowcast): Detectar variações no comportamento da séries temporais conforme elas ocorram Dosagem de Hormônios ou de sinais vitais em CTI Predição (forecast) : prever o comportamento futuro de uma serie Predição de epidemias Atualização (nowcast): predição sobre o presente corrigir atraso de notificações 3.7 Estacionariedade Uma série temporal é dita estacionária quando ela se desenvolve no tempo aleatoriamente ao redor de uma média constante e com uma variância constante, refletindo alguma forma de equilíbrio estável. Na prática, a maioria das séries que encontramos apresentam algum tipo de não estacionariedade, como por exemplo, tendência. O modelo mais simples de uma séries temporal estacionária pode ser representado por: \\[Z_t = \\mu + a_t\\] Sendo \\(\\mu\\) a média do processo temporal e \\(a_t\\) a componente aleatória, chama de Ruído Branco em análises de séries temporais. A estacionariedade da séries temporais pode ser: 1\\(^a\\) ordem - média constante ao longo de todo o período 2\\(^a\\) ordem - variância constante ao longo de todo o período 3.7.1 Função de Autocovariância de um processo estacionário \\[\\gamma_h = E{\\{[Z_t - E(Z_t)][Z_{t-h} - E(Z_{t-h})]\\}}\\] A covariância não depende do tempo, mas da distância entre as observações. Um processo é considerado fracamente estacionário se: \\(E(Z_t)=\\mu\\), \\(\\forall t\\) (constante) \\(var(Z_t) = \\sigma^2\\), \\(\\forall t\\) (constante) \\(Cov(Z_t, Z_{t-h}) = \\gamma_h\\), \\(\\forall t\\) (não depende do instante no tempo, apenas da distância h) Sendo o ruído branco (White Noise), também chamado de Processo Puramente Randômico, uma variável aleatória \\(a_t\\), com média zero e variância \\(\\sigma²_a\\): \\(a_t \\sim N(0, \\sigma^2_a)\\) \\(Cov(a_t, a_{t-h}) = 0\\), \\(\\forall h \\neq 0\\) (Não correlacionados) 3.7.2 Por que a estacionariedade é importante ? A maioria das técnicas estatísticas utilizadas em séries temporais supõe que estas sejam estacionárias. Caso a série temporal não seja estacionária, será necessário transformar os dados. A transformação mais comum consiste em tomar diferenças sucessivas da série original, até se obter uma série estacionária. A primeira diferença de \\(Z_t\\): \\[\\bigtriangledown Z_t = Z_t - Z_{t-1}\\] A segunda diferença de \\(Z_t\\): \\[\\bigtriangledown^{2} Z_t = \\bigtriangledown[\\Delta Z_t] = \\bigtriangledown[Z_t - Z_{t-1}]\\] A n-ésima diferença de \\(Z_t\\): \\[\\bigtriangledown^{n} Z_t = \\bigtriangledown[\\bigtriangledown^{n-1} Z_t]\\] Logaritmo dos dados - Estabilizar a variância \\[\\bigtriangledown log Z_t = log Z_t - log Z_{t-1}\\] Transformações Box-Cox Pode-se diferenciar tantas vezes quanto necessário até estabilizar (porém, em geral se diferencia apenas uma vez, raramente duas vezes). Como saber se um processo é estacionário ? Visualizando a série, aplicando a decomposição, boxplots, etc. Testes Estatísticos, ex: Dickey-Fuller 3.8 Pressuposto da Independência Os métodos usuais de análise estatística de dados têm como pressuposto básico a independência dos eventos (casos). Ou seja, a ocorrência de um caso de doença em uma dada pessoa seria independente da ocorrência em outra pessoa. Pressupostos básicos para uma análise de regressão: \\(E(e_i) = 0\\) Variância \\(\\sigma^2\\) constante (homocedasticidade); \\(e_i \\sim N(0, \\sigma^2)\\) \\(e_i \\neq e_j\\), são independentes Na análise da incidência de doenças (ou qualquer outro indicador ecológico) ao longo do tempo isso não é verdade: a incidência em um determinado dia/mês ou ano em geral é correlacionada com a ocorrência no dia/mês/ano anterior. Esta correlação é expressa em uma função denominada função de autocorrelação. 3.9 Dependência serial Quanto à dependência, séries temporais podem possuir: Independência (sem dependência serial): série puramente aleatória ou ruído branco; Memória longa: a dependência desaparece lentamente (os valores de pontos no passado influenciam momentos muito adiante no tempo - exemplo: doenças com grande latência como hanseníase); Memória curta: dependência desaparece rapidamente (doenças de alta infecciosidade e “explosivas”\" - exemplo: influenza). 3.10 Função de Autocorrelação - FAC (Autocorrelation function - ACF) O coeficiente de correlação entre \\(Z_{t}\\) e \\(Z_{t-h}\\) é chamado de autocorrelação de h-ésima ordem e é denotadado por: \\[ {\\rho}_{k}=\\frac {Cov\\left({Z}_{t},{Z}_{t-h} \\right)}{\\sqrt{Var\\left({Z}_{t},{Z}_{t-h} \\right)}} =\\frac{Cov\\left({Z}_{t},{Z}_{t-h} \\right)}{Var\\left({Z}_{t} \\right)} =\\frac{{\\gamma}_{k}}{{\\gamma}_{0}} \\] Temos então: \\({\\rho}_{0}=1\\) \\(-1\\leq {\\rho}_{l} \\leq 1\\) Um conjunto de autocorrelações, \\(\\left\\{\\rho_{h}\\right\\}\\), é chamado de função de autocorrelação de \\(Z_{t}\\). Para uma dada amostra, \\(\\left\\{Z_{t}\\right\\}_{t=1}^{T}\\), suponha que \\(\\overline{Z}\\) é a média amostral. Então, a autocorrelação amostral de primeira ordem de \\(Z_{t}\\) pode ser definida como: \\[ {\\hat{\\rho}}_{1}=\\frac{\\sum _{t=2}^{T}{\\left({Z}_{t}-\\overline{Z}\\right) \\left({Z}_{t-1}-\\overline{Z}\\right)}}{\\sum_{t=1}^{T}{{\\left({Z}_{t}-\\overline{Z}\\right)}^{2}}} \\] que é um estimador consistente de \\({\\rho}_{1}\\). Em geral, a autocorrelação amostral de h-ésima ordem de \\(Z_{t}\\) pode ser definida como: \\[ {\\hat{\\rho}}_{h}=\\frac{\\sum_{t=h+1}^{T}{\\left({Z}_{t}-\\overline{Z}\\right) \\left({Z}_{t-h}-\\overline{Z} \\right)}}{\\sum_{t=1}^{T}{{\\left({Z}_{t}-\\overline{Z}\\right)}^{2}}} \\] para \\(0\\leq h \\leq T-1\\). Por exemplo, suponha que você está avaliando uma série temporal qualquer e quer visualizar como as defasagens da série podem impactar seu valor atual (ou seja, se \\(Z_{t}\\) é relacionado com \\(Z_{t-h}\\) para \\(k\\ge1\\)). A função de autocorrelação pode ser usada para obter tal informação. Num primeiro momento, visualize os dados da série para 10 lags (defasagens). Observe que os lags se tornam novas colunas e na medida que elas aumentam, incrementa-se as linhas sem observações. Apesar da simples correlação entre os dados nos ajudar a identificar defasagens que poderíam contribuir para o comportamento da série em \\(t\\), precisamos fazer uso de testes estatísticos que verifiquem a significância da relação entre o valor atual e suas lags. Neste sentido, a função de autocorrelação tem grande importância. Abaixo, um exemplo de função de autocorrelação. Observe que há duas linhas horizontais que representam os limites do teste de significância sendo que valores acima ou abaixo da linha são estatisticamente significantes. Neste documento, apresentaremos o teste que é realizado. O correlograma é uma das principais ferramentas de análise exploratória em séries temporais, pois indica como cada valor em um dado instante de tempo \\(t\\) se relaciona com os valores em \\(t+1, t+2,...,t+j\\) Para um dado \\(h\\), os resultados da Função de Autocorrelação podem ser testados usando um teste que pode ser representado pelas seguintes hipóteses: \\[ \\begin{aligned} &amp;&amp; H_{0}: \\rho_{h}=0 \\\\ &amp;&amp; H_{1}: \\rho_{h}\\neq 0 \\end{aligned} \\] 3.11 Componentes de uma Série Temporal As séries temporais podem ser separadas em componentes sistemáticas (apontam movimentos regulares) e não sistemáticas (apontam movimentos irregulares). São elas: Componentes Sistemáticas (podem ou não estar presentes) Tendência Sazonalidade Ciclo Componentes Não Sistemáticas Aleatória ou Ruído Branco As análises exploratórias de séries temporais buscam isolar e interpretar as componentes. Tais componentes podem atuar de maneira isolada ou inter-relacionadas. 3.12 Tendência É a indicadora da direção global dos dados (ou movimento geral da variável), do percurso traçado e de sua linha contínua; É o efeito de longo prazo na média. Pode ser o aumento ou redução a longo prazo… 3.13 Sazonalidade São ciclos de curto prazo (não maiores que um ano), em torno da tendência; Costumam se referir a eventos ligados a estação do ano, vinculados ao calendário e geralmente repetidos a cada doze meses; Efeitos ligados à variações periódicas (semanal, mensal, anual, etc.); Padrões que ocorrem em intervalos fixos. Ex: Medidas de Temperatura (aumenta no verão e diminui no inverno). 3.14 Ciclo Os ciclos são oscilações (aproximadamente regulares) em torno da tendência. Podem dever-se a fenômenos naturais, socioculturais ou econômicos, como variações climáticas (ex: excesso ou falta de chuva pode produzir ciclos agrícolas) Variações que apesar de periódicas não são associadas automaticamente a nenhuma medida do calendário; Aumento ou redução de frequência sem intervalos fixos. Ex: Ciclos Econômicos e Ciclos de epidemias. A diferença entre os ciclos, propriamente ditos, e a sazonalidade é o período de avaliação (curto e longo); A semelhança é que ambos definem oscilações relativamente regulares em torno da tendência. Na área de saúde é pouco comum encontrarmos ciclos, ainda que possam existir. 3.14.1 Como detectar a sazonalidade ? Visualmente Boxplots seasonplot monthplot decomposição 3.15 Termo Aleatório ou Ruído Branco Conceitualmente, a componente aleatória é uma mistura de pertubações bruscas, irregulares e esporádicas nos movimentos das séries que tipificam os fenômenos. Na realidade é resultante dos efeitos de múltiplas causas que dificilmente/não conseguem ser previstos. Exemplos típicos de eventos aleatórios: Secas Enchentes Terremotos Ocorrência de epidemias Crise política Conflitos Socioeconômicos 3.16 Composição dos Modelos de séries temporais A série pode ser descrita como sendo a soma ou multiplicação dos componentes (tendência, sazonalidade, ciclicidade - se houver - e termo aleatório). 3.16.1 Modelo Aditivo \\[Z_t = T_t + S_t + a_t\\] sendo \\(t = 1,2, ..., N\\) Essa composição de modelo sugere que a variação sazonal parece constante, não muda quando da série temporal aumenta. 3.16.2 Modelo Multiplicativo \\[Z_t = T_t . S_t . a_t\\] Essa composição de modelo sugere que a sazonalidade varia em conjunto com a tendência (aumenta de amplitude quando aumenta a tendência). Pode ser transformado em aditivo usando \\(log\\). \\[log(Z_t) = log(T_t . S_t . a_t) = log(T_t) + log(S_t) + log(a_t)\\] 3.17 Decomposição de séries temporais 3.18 Prática no R 3.18.1 A biblioteca ts é a mais utilizada no R Na biblioteca ts a função mais utilizada tem o mesmo nome ts , não é necessário chamar library(ts) pois a mesma já se encontra carregada por default. A função ts tem como argumentos principais: data: um vetor, data.frame ou matriz com dados para a série start: tempo da primeira observação e/ou end: tempo da última observação frequency: quantidade de observações por unidade de tempo, podendo representar: Anual = 1, Trimestral = 4, Mensal = 12 e Semanal = 52 3.18.2 Simulando uma Série Temporal Vamos simular uma série usando a função rnorm para gerar 60 pontos aleatórios , com media 0 e desvio 1 em seguida vamos usar a função ts para transformar o vetor em uma objeto ts e finalmente fazer um gráfico. # Uma serie temporal normalmente distribuída serie &lt;- rnorm(60) # usando a função ts para criar um objeto da classe ts # pode-se usar também end=c(2016,12) mas basta um! serie.ts &lt;- ts(serie,start = c(2012,1), frequency=12) Vamos observar agora como é um objeto do tipo ts serie.ts Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 2012 -0.850789274 1.098551160 -1.206355025 0.581862276 0.863689895 0.983052004 -1.271260251 -0.001062756 -0.960910158 1.259209306 -0.866606890 0.249044190 2013 -0.086168223 -0.492884341 -0.268998914 -0.399240236 -0.944297510 1.013188332 -0.408704068 -0.181086790 1.183755855 -1.608494491 -2.272439862 -2.040607916 2014 -0.648006354 0.717722237 -0.103400012 0.327017362 -0.977597331 0.341442983 0.043822392 -1.021578363 0.793427719 0.501624458 -1.554470354 0.883497837 2015 -0.207767801 1.831374014 0.177264382 -0.805840648 1.947932470 0.121197052 -0.354949127 1.052866250 1.163113962 -0.798832818 0.775455294 -1.995007352 2016 -0.350562193 0.380864742 0.258213780 0.964510263 -0.491278153 0.081638756 -0.161770723 1.272817069 -0.720269271 1.541051559 0.853661550 0.802399491 Para se obter o gráfico basta usar a função plot # gráfico da série plot(serie.ts) 3.18.3 Importando uma vetor e transformando em Série Temporal Vamos usar agora um exemplo de casos caxumba em Nova York de 1928-1972 proveniente do livro: Yorke, J.A. and London, W.P. (1973) “Recurrent Outbreaks of Measles, Chickenpox and Mumps”, American Journal of Epidemiology, Vol. 98, pp.469 Observe que a partir de um dado puramente vetorial já podemos obter um objeto ts Clique aqui para ver como são os dados brutos Para ler os dados utilizaremos a função scan que importa dados vetoriais. Nesse exemplo estaremos usando os dados diretos de uma URL mas o dado poderia estar no seu disco, assim você importaria localmente! OBSERVAÇÃO: No MS-Windows existe algum problema ao acessar sites seguros (HTTPS) assim vamos definir uma função que permita o acesso a esse tipo de site. podemos tentar duas coisas: options(url.method=&quot;libcurl&quot;) Ou criar uma função: scan.win &lt;- function(x) {scan(url(x,method = &#39;libcurl&#39;))} No Windows 10 aparentemente não é necessário o procedimento acima mas fique atento que ao longo do curso estaremos importando dados com frequência. Descubra como fazer essa importação funcionar no seu computador! Exemplo com dados de Caxumba, não se esqueça de definir a função acima! dados &lt;- scan(&#39;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/exemplos/caxumba.dat&#39;) caxumba &lt;- ts(dados,start = c(1928,1),frequency = 12) plot(caxumba) 3.18.4 Utilizando dados da incidência de dengue nas Filipinas, 2008 - 2016 Exemplo serie mensal da Incidência de dengue por 100,000hab em uma região das Filipinas de 2008 to 2016. Fonte: Kaggle dengue &lt;- read.csv(&quot;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/dados/denguecases2.csv&quot;) head(dengue) ## Month Year Dengue_Cases ## 1 Apr 2008 131.13331 ## 2 Aug 2008 159.97741 ## 3 Dec 2008 93.65630 ## 4 Feb 2008 49.38712 ## 5 Jan 2008 79.85915 ## 6 Jul 2008 152.63940 Antes de colocando em formato de série temporal utilizando a biblioteca ts do R, precisamos ordenar o dataframe para que possamos transformar corretamente em uma série temporal uma vez que a função baseia-se somente na ordem de entrada. Assim vamos alterar a coluna Month em um fator para que possamos manter a ordem dos meses e em seguida usar a função order para reordenar todo o dataframe. dengue$Month &lt;- factor(dengue$Month,levels = month.abb) dengue &lt;- dengue[order(dengue$Year,dengue$Month),] head(dengue) ## Month Year Dengue_Cases ## 5 Jan 2008 79.85915 ## 4 Feb 2008 49.38712 ## 8 Mar 2008 115.13416 ## 1 Apr 2008 131.13331 ## 9 May 2008 129.20466 ## 7 Jun 2008 210.24223 Com o dado na devida ordem e podemos continuar a transformação em série temporal. # Convertendo os dados para o formato de Séries Temporais # A frequency=12 foi especificado pois queremos mostrar dos dados mensais denguets &lt;- ts(dengue$Dengue_Cases,start=c(2008,1),frequency=12) plot(denguets, ylab=&quot;Casos de Dengue&quot;, xlab=&quot;Tempo&quot;) Verificando e testando a autocorrelação dos casos de dengue. \\[ \\begin{aligned} &amp;&amp; H_{0}: \\rho_{h}=0 \\\\ &amp;&amp; H_{1}: \\rho_{h}\\neq 0 \\end{aligned} \\] acf(denguets, lag.max=20, main=&quot;Função de Autocorrelação&quot;) Box.test(denguets, lag=20, type=&quot;Ljung-Box&quot;) Box-Ljung test data: denguets X-squared = 271.51, df = 20, p-value &lt; 2.2e-16 Através do gráfico e do teste do ACF, é possível verificar que a incidência de dengue é correlacionada ao longo do tempo. Fazendo uma análise descritiva da série temporal denguets Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 2008 79.85915 49.38712 115.13416 131.13331 129.20466 210.24223 152.63940 159.97741 307.65474 58.74152 36.17346 93.65630 2009 87.96879 96.47914 190.36630 98.15255 124.03703 215.76350 40.66555 39.54446 85.84889 70.55726 95.37771 171.74569 2010 81.62430 95.59756 174.13877 33.54686 32.44285 60.04658 55.22568 90.16454 135.63883 74.17619 71.39315 138.44613 2011 33.66412 46.52083 93.34766 58.76998 134.83900 187.12547 109.27259 88.23193 143.89752 53.87635 91.05780 184.88198 2012 114.48472 251.27249 400.20592 162.21779 191.47219 276.13014 75.88479 128.88087 423.70277 239.40052 421.72803 607.49949 2013 244.44260 374.95060 530.46735 75.91858 132.94225 678.00967 387.48040 448.67952 515.58071 303.43820 530.61714 696.56174 2014 56.28797 113.67882 522.16422 249.49254 326.64717 366.61897 237.79033 509.79051 469.48018 41.43502 87.44494 226.41755 2015 134.40762 255.93445 243.46980 212.50300 485.76066 331.08272 33.81837 60.95752 121.16441 104.00878 210.63816 160.61858 2016 201.73756 362.34941 270.55192 18.94775 57.02598 57.41445 70.58666 145.36292 116.41069 119.08265 245.19665 194.46347 Vamos verificar a propriedades da série: Estatística Função R Valor Comprimento da Serie length() 108 media mean() 192.0458131 mediana median() 134.62331 máximo max() 696.56174 minimo min() 18.947748 amplitude range() 18.947748, 696.56174 frequência frequency() 12 período de inicio start() 2008, 1 período de fim end() 2016, 12 Pode-se pedir também o sumário da série! summary(denguets) Min. 1st Qu. Median Mean 3rd Qu. Max. 18.95 81.18 134.62 192.05 246.27 696.56 hist(denguets,breaks = 10) boxplot(denguets,col=&#39;lightblue&#39;) Mudando a janela de tempo da série temporal: observando apenas os dados de Jan 2010 até Dez de 2012. denguets2 &lt;- window(denguets, start=c(2010,1),end=c(2012,12),frequency=12) plot(denguets2, ylab=&quot;Casos de Dengue&quot;, xlab=&quot;Tempo&quot;) Decompondo a série temporal Decompondo a série temporal dos casos de dengue via método clássico decompose (Decomposição via Médias Móveis): plot(decompose(denguets)) Decompondo a série temporal dos casos de dengue via STL (Seasonal and Trend decomposition using Loess): É mais robusta, mais sensível a vários tipos de sazonalidade e lida melhor com os outliers. plot(stl(denguets, s.window=&quot;periodic&quot;)) decom_dengue &lt;- stl(denguets,12) head(decom_dengue$time.series) seasonal trend remainder Jan 2008 -71.00930 132.7212 18.147256 Feb 2008 -26.81769 132.8553 -56.650467 Mar 2008 81.88596 132.9894 -99.741166 Apr 2008 -65.11369 133.1235 63.123548 May 2008 -22.99327 132.7289 19.468992 Jun 2008 80.32281 132.3344 -2.415003 plot(decom_dengue) Trend &lt;- decom_dengue$time.series[,2] Seasonal &lt;- decom_dengue$time.series[,1] Random &lt;- decom_dengue$time.series[,3] Refazendo o sinal original da séries temporais através das componentes: recomposed_dengue &lt;- Trend+Seasonal+Random par(mfrow=c(1,2)) plot(denguets, ylab=&quot;Incidência Dengue&quot;, main=&quot;Original&quot;) plot(as.ts(recomposed_dengue), ylab=&quot;Incidência Dengue&quot;, main=&quot;Recomposta&quot;) Em algumas séries temporais não é fácil avaliar suas componentes de maneira visual, ou seja, de maneira gráfica. Para podermos avaliar melhor precisamos utilizar alguns testes estatísticos. Outra forma de fazer gráficos é através das bibliotecas ggplot e ggfortify: library(ggplot2) library(ggfortify) autoplot(denguets) autoplot(decompose(denguets)) Avaliando a Estacionariedade da série temporal Segundo o teste de Dickey-Fuller: \\(H_{0}\\): A série temporal não é Estacionária \\(H_{1}\\): A série temporal é Estacionária Alguns exemplos: Testando a estacionariedade da série dos casos de dengue: library(tseries) adf.test(denguets) Augmented Dickey-Fuller Test data: denguets Dickey-Fuller = -1.9795, Lag order = 4, p-value = 0.5851 alternative hypothesis: stationary Como p-valor = 0,5851, não rejeitamos a hipótese nula, ou seja, não há indícios da série temporal ser estacionária. Avaliando a tendência em uma série temporal Construindo uma reta baseado no modelo de regressão linear simples para verificar a tendência da incidência da dengue: plot(denguets, main = &quot;Incidência de Dengue 2008 a 2016&quot;) abline(reg=lm(denguets ~ time(denguets)), col = &quot;red&quot;) Construindo uma curva suavizada baseada na função lowess para verificar tendência da incidência da dengue: plot(denguets, ylab=&quot;Casos de Dengue&quot;, xlab=&quot;Tempo&quot;) library(Kendall) lines(lowess(time(denguets),denguets),lwd=3, col=2) Uma outra forma de mostrar a tendência da série temporal é fazendo a média anual. Observe que a curva se parece um pouco com a curva do lowess porém menos suave. plot(aggregate(denguets, FUN=mean)) Avaliando a Sazonalidade da série temporal De maneira visual podemos utilizar algumas técnicas gráficas, tais como: Boxplot boxplot(denguets ~ cycle(denguets)) Monthplot monthplot(denguets) Seasonplot (funçao disponibilizada pela library forecast) library(forecast) seasonplot(denguets,col=terrain.colors(6),lwd=2) 3.19 Exercícios Propostos Utilizando os bancos: Série mensal de óbitos por doenças respiratórias na região Sul do Brasil de 1996 a 2017 (pode ser acessado na URL https://bit.ly/2P4CJj4, fonte: DataSUS/MS) Série semanal do numero de casos Malaria nos EUA de 1974 a 1984 (pode ser acessado na URL https://bit.ly/2KMXsCC, fonte:CDC/US) Importe a série para um formato ts e faça: Uma análise exploratórias dos dados em formato séries temporais; Decomponha a série temporal; Através de análises gráficas e/ou testes estatísticos, avalie e verifique a existência de tendência e sazonalidade na série. 3.20 Outros materiais sobre Séries Temporais Time Series Task View: https://cran.r-project.org/web/views/TimeSeries.html Blog, Ebook and Forecast Documentation by Rob Hyndman: https://otexts.org/fpp2/intro.html Extracting Seasonality and Trend from Data: Decomposition Using R https://anomaly.io/seasonal-trend-decomposition-in-r/index.html STL: A seasonal-trend decomposition procedure based on loess https://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/stl-a-seasonal-trend-decomposition-procedure-based-on-loess.pdf) Stackoverflow Community: https://stackoverflow.com/questions 3.21 Bibliografia sugerida DIGGLE, Peter. Time Series: A Biostatistical Introduction (Oxford Statistical Science Series, No. 5) 1st Edition, 1996 FERREIRA, Pedro Guilherme Costa. Análise de Séries Temporais em R: curso introdutório. 2018. METCALFE, Andrew V.; COWPERTWAIT, Paul SP. Introductory time series with R. Springer-Verlag New York, 2009. MORETTIN, Pedro A.; TOLOI, Clélia M.C. Análise de Séries Temporais: Modelos Lineares Univariados. Bluscher - ABE - Projeto Fisher. Edição 3, 2018. WOODWARD, Wayne A.; GRAY, Henry L.; ELLIOTT, Alan C. Applied time series analysis with R. CRC press, 2017. "],["transformações-e-suavizações.html", " 4 Transformações e Suavizações 4.1 Introdução 4.2 Transfomação dos dados em ST 4.3 Métodos de Alisamento ou Suavização 4.4 Médias móveis 4.5 Kernel 4.6 Loess / Lowess 4.7 Splines 4.8 Exercícios Propostos 4.9 Bibliografia sugerida", " 4 Transformações e Suavizações 4.1 Introdução As transformações e as funções de alisamento (suavização) em séries temporais são normalmente empregados para nos ajudar a ver melhor os padrões existentes - tais como as tendências e sazonalidade - e suavizar as oscilações irregulares (ruídos) para que possamos obter uma série mais limpa com um sinal mais claro. Estas técnicas não nos fornecem um modelo, mas podem ser um bom primeiro passo na descrição para os vários componentes da série. 4.2 Transfomação dos dados em ST Alguns exemplos: Utilização de funções: Logarítmicas, Potências, Exponenciais, ou transformação Box-Cox. Diferenciação: Séries não estacionárias. Objetivo é transformar a série em estacionária, estabilizando a média ( \\(\\bigtriangledown Z_t\\) ). Box-Cox: Estabiliza a variância. (também o log , sqrt etc…) Médias Móveis: Permite a suavização dos dados da ST. Reduz outliers e captura a tendência. Outras técnicas de suavização: Kernel, Loess/Lowess, Splines e Generalized Additive Model (GAM). Para demostrar o resultado dessas transformações, iremos aplicar algumas dessas técnicas. 4.2.1 Transformações Box-Cox, Diferenciação e Logarítmica Esta é uma técnica de transformação de dados útil para estabilizar a variância, tornar os dados mais semelhantes à distribuição normal, melhorar a validade das medidas de associação e para outros procedimentos de estabilização de dados. Box and Cox (1964) propuseram uma transformação na variável da ST \\(Z_t\\), que depende do parâmetro \\(\\lambda\\) da seguinte forma: \\[ Z_{t}(\\lambda) = \\left\\{ \\begin{array}{rc} Z_t^{\\lambda}, &amp;\\mbox{se} \\quad \\lambda \\neq 0, \\\\ ln(Z_t) , &amp;\\mbox{se} \\quad \\lambda = 0. \\end{array}\\right.\\] Se o valor de \\(\\lambda\\) é igual a zero, a transformação logarítmica da sequência inicial é realizada. Se o valor de lambda difere de zero, a transformação é por lei exponencial. Quando \\(\\lambda\\) = 1, a série é analisada em sua escala original. \\(\\lambda = 1/2\\) corresponde à transformação da raiz quadrada. Para que a transformação seja aplicável, a série deve ser estritamente positiva. Ex: Utilizando os dados do dataset Air Passengers, temos: library(forecast) par(mfrow=c(3,2)) # Série original plot(AirPassengers, ylab=&quot;Passageiros&quot;, main=&quot;Original&quot;) # Lambda = 0, Logaritmica t1 &lt;- BoxCox(AirPassengers,lambda =0 ) plot(t1, ylab=&quot;Passageiros&quot;, main=&quot;Lambda = 0, Logaritmica&quot;) # Lambda = 0.1 t2 &lt;- BoxCox(AirPassengers,lambda =.1 ) plot(t2, ylab=&quot;Passageiros&quot;, main=&quot;Lambda = 0.1&quot;) # Gera labda automático lbd &lt;- BoxCox.lambda(AirPassengers) # print(lbd) t3 &lt;- BoxCox(AirPassengers,lambda =lbd ) plot(t3, ylab=&quot;Passageiros&quot;, main=paste0(&quot;Lambda Automático (&quot;,round(lbd,4),&quot;)&quot;)) # Diferenciação t4 &lt;- diff(AirPassengers) plot(t4, ylab=&quot;Passageiros&quot;, main=&quot;Diferenciação &quot;) # Logarítmo t5 &lt;- diff(log(AirPassengers)) plot(t5, ylab=&quot;Passageiros&quot;, main=&quot;Diferença do Log&quot;) 4.3 Métodos de Alisamento ou Suavização Uma função é suave quando contínua e derivável em todos os pontos. Utiliza-se a expressão Funções de Suavização para definir funções que, aplicadas sobre um conjunto numérico, retornam outro conjunto cujos valores tendem à média (local ou global). Funções de suavização são utilizadas quando se supõe que o fenômeno é, de fato, suave, e as observações apresentam variabilidade aleatória pouco relevante. Também são utilizadas quando se deseja modelar a estrutura geral o fenômeno, desconsiderando cada ocorência isolada. 4.3.1 Algumas funções de suavização Existem diversos tipos de funções de suavização no R. Dentre as principais, destacamos: Médias móveis: O método mais simples de suavização. Kernel density: Estimativa de densidade de probabilidade – equivale à uma média ponderada. Loess/Lowess: locally (weighted) estimated scatterplot smoothing – estende a mesma idéia, mas os valores entram em uma regressão (ponderada ou não), retornando não apenas a média, mas também uma inclinação (\\(\\beta\\)). Splines: cúbica, quadrática, p-splines, thin plate splines etc… Todas essas funções podem ser uni ou multi-dimensionais. Existem ainda várias outras funções para suavizar. 4.4 Médias móveis Considere a ST estacionária e localmente constante, composta de seu nível e mais um ruído aleatório: \\[ Z_t = \\mu_t + a_t , \\] \\[t = 1,2,...,N \\] Sendo \\(E(a_t) = 0\\), \\(Var(a_t)=\\sigma^2_a\\) e \\(\\mu_t\\) é um parâmetro desconhecido que varia com o tempo. A técnica de média móvel consiste em calcular a média aritmética das \\(h\\) observcações mais recentes, ou seja: \\[M_t = \\dfrac{Z_t+Z_{t-1}+...+Z_{t-h+1}}{h}\\] Denotamos por \\(h\\) o comprimento da média. Desta forma, \\(M_t\\) é uma estimativa do nível \\(\\mu_t\\) que não leva em consideração as observações mais antigas. Note que a cada período a observação mais antiga é substituída pela mais recente, calculando-se uma média nova. Vamos exemplificar o que acontece quando se usa uma janela de 3 meses. Repare as 3 primeiras observações na série original: Agroa a série com Média Móvel 3. Note que o primeiro e o último valores da série agora são NA: Observe que o valor para fevereiro é calculado a partir dos 3 primeiros valores. (16.87 + 15.08 + 15.07)/3 = 15.67 Note que o exemplo acima é uma media móvel centrada com uma janela de 3 meses. Nesse caso, se perde o primeiro e o último pontos da série. Existe ainda a possibilidade de se alinhar a media móvel à direita ou à esquerda, sendo a media centrada o default na grande maioria das funções. Exemplo: Utilizando a ST mensal de mortes em estradas no Reino Unido (1969–1984), temos : library(forecast) plot(UKDriverDeaths,ylab=&#39;&#39;,main=&quot;Média Móvel Centrada&quot;) lines(ma(UKDriverDeaths,12),col=2,lty=1,lwd=2) lines(ma(UKDriverDeaths,4),col=4,lty=2,lwd=2) legend(&quot;topright&quot;,legend=c(&quot;Óbitos&quot;,&quot;Média Móvel 4&quot;,&quot;Média Móvel 12&quot;), col = c(&quot;black&quot;,&#39;blue&#39;,&#39;red&#39;), lty=c(1,2,1), cex=1) Existem muitas funções em diversos pacotes que possibilitam fazer a media móvel. No exemplo anterior, usamos a função ma() do pacote forecast. Vamos a seguir usar a função rollmean() do pacote zoo, mostrando como ficariam as médias móveis com esses outros alinhamentos. plot(UKDriverDeaths,ylab=&#39;&#39;,main=&quot;Média Móvel alinhada à direita&quot;) lines(zoo::rollmean(UKDriverDeaths,k=6,align = &#39;right&#39;),col=4,lwd=2) plot(UKDriverDeaths,ylab=&#39;&#39;,main=&quot;Média Móvel alinhada à esquerda&quot;) lines(zoo::rollmean(UKDriverDeaths,k=6,align = &#39;left&#39;),col=6,lwd=2) 4.4.1 Utilização das Médias Móveis Processo de Transformação - “Suavização da Série” Remoção de outliers Identificação de tendências Ex: Médias Móveis - ordem 5 4.5 Kernel O algoritmo: Seja \\((x)\\) ponto para o qual se deseja estimar f(.) Defina a função kernel: simétrica, unimodal, centrada em \\((x)\\), que cai a zero nos limites da vizinhança. Esse subconjunto dos dados, também denominado janela, largura de banda ou parâmetro de suavização controla flexibilidade do kernel. Repita o procedimento para diversos \\((x)\\) Conecte os pontos \\[\\hat{f_h}(x) = \\dfrac{1}{Nh}\\sum{K \\left( \\dfrac{x-x_i}{h}\\right)}\\] \\(h\\) \\(\\rightarrow\\) largura de banda \\(K\\) \\(\\rightarrow\\) função de suavização Kernel Gaussiano: \\[k(x)=\\dfrac{1}{\\sqrt{2\\pi}} exp(1/2 x^2)\\] 4.5.1 Diferentes Funções Kernel Vamos a uma demostração: Ao chamar a função demo() você vai ver um painel de controle como o abaixo: E uma gráfico de uma função kernel como abaixo. Utilize o controle deslizante mostrado pela seta e altere as opções. Série Temporal: Leptospirose vs Clima. #declara local na internet onde estão os dados local &lt;- &quot;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/dados/&quot; ## a função paste0 junta o local e o nome do arquivo! lepto &lt;- read.csv2(paste0(local,&quot;leptoruido.csv&quot;), header=T) dia &lt;- read.table(paste0(local,&quot;climadia.dat&quot;), header=T) library(lattice) library(car) library(sm) library(survival) #XY condicionado xyplot(cases + totrain + tempmed ~ week, outer=TRUE, layout=c(1, 3), pch=1, type=&quot;l&quot;,ylab=&quot;&quot;, scales=list(x=list(relation=&#39;same&#39;), y=list(relation=&#39;free&#39;)), data=lepto) Exemplos de Kernel em histogramas #### density - default &quot;gaussian&quot; hist(lepto$totrain, breaks=seq(0,400,by=10),freq=F, col=&quot;darkgray&quot;, main = &quot;Chuva&quot;) lines(density(lepto$totrain , 4),col=2) lines(density(lepto$totrain , 12),col=&quot;blue&quot;) legend(&quot;topright&quot;, c(&quot;4&quot;,&quot;12&quot;), title=&quot;BW&quot;, col=c(2,&quot;blue&quot;), lty=c(1,1)) hist(lepto$cases, breaks=seq(0,36,by=1),freq=F, col=&quot;darkgray&quot;, main = &quot;Casos Leptospirose&quot;) lines(density(lepto$cases , 1),col=2) lines(density(lepto$cases , 2),col=&quot;green&quot;) lines(density(lepto$cases , 4),col=&quot;blue&quot;) legend(&quot;topright&quot;, c(&quot;1&quot;,&quot;2&quot;,&quot;4&quot;), title=&quot;BW&quot;, col=c(2,&quot;green&quot;,&quot;blue&quot;), lty=c(1,1,1)) hist(lepto$cases, breaks=seq(0,36,by=1),freq=F, col=&quot;darkgray&quot;) lines(density(lepto$cases , 2, kernel = &quot;rectangular&quot; ),col=2) lines(density(lepto$cases , 2, kernel = &quot;triangular&quot; ),col=&quot;green&quot;) lines(density(lepto$cases , 2, kernel = &quot;gaussian&quot; ),col=&quot;blue&quot;) legend(&quot;topright&quot;, c(&quot;retangular&quot;,&quot;triangular&quot;,&quot;gaussiano&quot;), title=&quot;BW&quot;, col=c(2,&quot;green&quot;,&quot;blue&quot;), lty=c(1,1,1)) Aplicando o Kernel em ST: plot(totrain ~ week, data=lepto, cex=.3, pch=19,col=&quot;gray35&quot;,ylab=&quot;Kernel Chuva&quot;, xlab=&quot;Semana&quot;, main=&quot;Kernel Smooth&quot;) lines(ksmooth(lepto$week, lepto$totrain, kernel = &quot;normal&quot;, bandwidth = 52), col=3) lines(ksmooth(lepto$week, lepto$totrain, kernel = &quot;normal&quot;, bandwidth = 21), lwd=2,col=7) lines(ksmooth(lepto$week, lepto$totrain, kernel = &quot;normal&quot;, bandwidth = 13), col=2) lines(ksmooth(lepto$week, lepto$totrain, kernel = &quot;normal&quot;, bandwidth = 4), col=4) legend(&quot;topright&quot;,c(&quot;52 sem.&quot;,&quot;21 sem.&quot;,&quot;13 sem.&quot;,&quot;4 sem.&quot;),fill=c(3,7,2,4), title=&quot;Janela&quot;,bty=&quot;n&quot;) 4.5.2 Largura de Banda Como estimar a largura de banda ? Validação cruzada \\[CV(\\lambda) = \\frac{1}{n} \\sum_{j=1}^n \\left( y_i - \\hat{f}_{\\lambda(j)} (x_j) \\right) ^2\\] O ponto deixado fora do ajuste a cada vez, \\(\\lambda\\) o valor que minimiza essa equação. ### efeito de borda # exluindo os pontos 1 a 3 para forcar borda lepto2 &lt;- lepto[-c(1,2,3),] hcv(lepto2$week, lepto2$totrain, display=&quot;lines&quot;) [1] 6.129 abline(v= 6.129356, col=2,lty=2) plot(totrain ~ week, data=lepto2, cex=.3, pch=19,col=&quot;gray35&quot;,ylab=&quot;Kernel Chuva&quot;, xlab=&quot;Semana&quot;, main=&quot;Kernel Smooth -- Efeito de Borda&quot;) lines(ksmooth(lepto$week, lepto$totrain, kernel = &quot;normal&quot;, bandwidth = 21 ), col=2) lines(ksmooth(lepto2$week, lepto2$totrain, kernel = &quot;normal&quot;, bandwidth = 6.1 ), col=1) legend(&quot;topright&quot;,c(&quot;21 sem.&quot;,&quot;6 sem.&quot;),fill=c(2,1), title=&quot;Janela&quot;,bty=&quot;n&quot;) 4.5.3 Utilização do Kernel Vantagens: simples, ótimo para análise exploratória. Desvantagens: efeito de borda. Muito sensível à largura de banda. Escolha automática de largura de banda pode não ser o desejável. Pouco sensível à forma da função, desde que suave. 4.6 Loess / Lowess Loess (Locally Estimated Scatterplot Smoothing) e lowess (Locally Weighted Scatterplot Smoothing) são funções semelhante ao kernel, mas os valores são estimados a partir de uma regressão local ao invés da média ponderada. No caso do loess a cada ponto do conjunto de dados um polinômio é ajustado utilizando uma reta a um sub-conjunto dos dados através de mínimos quadrados. Já para o lowess, é ajustada uma reta por mínimos quadrados ponderados de forma a dar maior peso aos pontos próximos. O subconjunto dos dados é também denominado janela, largura de banda ou parâmetro de suavização e controla flexibilidade da função de regressão – se a janela for igual ao total de pontos fica igual à regressão. Quanto maior o tamanho da janela, maior o alisamento e vice-versa. O grau do polinômio de cada regressão local em geral é baixo. Polinômio de primeiro grau é a regressão linear local; de segundo regressão quadrática. A largura da janela é indicado por uma fração dos dados que varia de 0 a 1. Exemplo: largura 0,1 significa que a janela tem largura que equivale a 10% do eixo horizontal; Polinômio de grau 0 é a média móvel; Se a janela for de 100% dos pontos = média. Existem varias funções que implementam o loess/lowess no R, por exemplo: lowess() e loess() . plot(lepto$week, lepto$totrain,cex=.3, pch=19, col=&quot;gray35&quot;,ylab=&quot;Lowess Chuva&quot;, xlab=&quot;Semana&quot;, main=&quot;Lowess - Bandwidth e Grau do Polinômio&quot;) lines(lowess(lepto$totrain ~ lepto$week, f = 0.75),col=4) lines(lowess(lepto$totrain ~ lepto$week, f = 0.015),col=2) legend(&quot;topright&quot;,c(&quot;f=0.75&quot;,&quot;f=0.015&quot;),col=c(4,2), title=&quot;&quot;,bty=&quot;n&quot;,lty=c(1,1)) # Loess – Span &amp; Grau plot(lepto$week, lepto$totrain,cex=.3, pch=19, col=&quot;gray35&quot;,ylab=&quot;Loess Chuva&quot;, xlab=&quot;Semana&quot;, main=&quot;Loess - Bandwidth e Grau do Polinômio&quot;) lines(predict(loess(totrain ~ week , data=lepto,span = 0.75, degree = 2)),col=2) lines(predict(loess(totrain ~ week , data=lepto,span = 0.75, degree = 1)),col=2,lwd=2,lty=2) lines(predict(loess(totrain ~ week , data=lepto,span = 0.05, degree = 2)),col=&quot;darkblue&quot;) lines(predict(loess(totrain ~ week , data=lepto,span = 0.05, degree = 1)),col=&quot;darkblue&quot;,lwd=2,lty=2) legend(&quot;topright&quot;,c(&quot;75% - 2º&quot;,&quot;75% - Linear (default)&quot;,&quot;5% - 2º&quot;,&quot;5% - Linear&quot;),lty=c(1,2,1,2), col=c(2,2,&quot;darkblue&quot;,&quot;darkblue&quot;), title=&quot;Janela e Grau&quot;,bty=&quot;n&quot;) # Loess – Span # lowess - f plot(lepto$week, lepto$totrain,cex=.3, pch=19, col=&quot;gray35&quot;,ylab=&quot;Loess Chuva&quot;, xlab=&quot;Semana&quot;, main=&quot;Loess - Bandwidth&quot;) lines(predict(loess(totrain ~ week , data=lepto,span = 0.15, degree = 2)),col=1, lwd=1.5) lines(predict(loess(totrain ~ week , data=lepto,span = 0.05, degree = 2)),col=2, lwd=1.5) lines(predict(loess(totrain ~ week , data=lepto,span = 0.10, degree = 2)),col=&quot;darkblue&quot;, lwd=1.5) legend(&quot;topright&quot;,c(&quot; 5% (21 sem.)&quot;,&quot;10% (41 sem.)&quot;,&quot;15% (61 sem.)&quot;),col=c(2,&quot;darkblue&quot;,1), lty=c(1,1,1),title=&quot;Janela&quot;,bty=&quot;n&quot;) # Loess – Span &amp; Borda plot(lepto$week, lepto$totrain,cex=.3, pch=19, col=&quot;gray35&quot;,ylab=&quot;Loess Chuva&quot;, xlab=&quot;Semana&quot;, main=&quot;Loess - Bandwidth&quot;) lines(predict(loess(totrain ~ week , data=lepto2,span = 0.15, degree = 2)),col=1, lwd=1.5) lines(predict(loess(totrain ~ week , data=lepto2,span = 0.05, degree = 2)),col=2, lwd=1.5) lines(predict(loess(totrain ~ week , data=lepto2,span = 0.10, degree = 2)),col=&quot;darkblue&quot;, lwd=1.5) legend(&quot;topright&quot;,c(&quot; 5% (21 sem.)&quot;,&quot;10% (41 sem.)&quot;,&quot;15% (61 sem.)&quot;),col=c(2,&quot;darkblue&quot;,1), lty=c(1,1,1),title=&quot;Janela&quot;,bty=&quot;n&quot;) # Loess – Outra forma, mas fica pouco suave scatter.smooth(lepto$week, lepto$tempmed, span = .05, degree = 2, family = &quot;gaussian&quot;, col= &quot;darkgray&quot;, cex=.5, ylab=&quot;Temperatura&quot;, xlab=&quot;Semana&quot;) scatter.smooth(lepto$week, lepto$totrain, span = .05, degree = 2, family = &quot;gaussian&quot;, col= &quot;darkgray&quot;, cex=.5, ylab=&quot;Chuva&quot;, xlab=&quot;Semana&quot;) scatter.smooth(lepto$week, lepto$cases, span = .05, degree = 2, family = &quot;gaussian&quot;, col= &quot;darkgray&quot;, cex=.5, ylab=&quot;Casos Leptospirose&quot;, xlab=&quot;Semana&quot;) 4.6.1 Utilização do loess/lowess Vantagens: simples, ótimo para análise exploratória. Menos sensível à borda. Desvantagens: pode ser sensível a valores extremos. 4.6.2 Comparando Kernel average smoother Local linear regression 4.7 Splines Splines são um conjunto de funções polinomiais que possuem muitos usos. No nosso caso, estaremos usando como uma função de suavização que juntam nós, de forma suave, mantendo propriedades matemáticas ótimas. A mais usada para este fim é a regressão penalizada chamada spline cúbica natural, com nós em valores distintos de \\(x_i\\). A escolha do parâmetro de suavização pode ser visual ou mais formal, quando a definição é dada pelo valor que minimiza o erro quadrático médio do ajuste, ou através de alguma forma de validação cruzada. Na regressão penalizada quer se encontrar a solução \\(\\hat{f}(x)\\) que minimize: \\[\\sum\\left[y_i - f(x_i) \\right]^2 + \\tau \\int f&#39;&#39;(x)]^2 dx\\] sendo \\(\\tau\\) o parâmetro de alisamento: Se \\(\\tau = 0 \\Rightarrow \\hat{f}(x)\\) é interpolação pontual (conecta os pontos) Se \\(\\tau = 1 \\Rightarrow \\hat{f}(x)\\) é interpolação linear simples Se \\(\\tau\\) é muito grande \\(\\Rightarrow \\hat{f}(x)\\) será tal que \\(f&#39;&#39;(x)\\) seja zero em todos os pontos, ou seja, mínimos quadrados. 4.7.1 Splines vs Loess/Lowess No spline se minimiza uma função-objetivo explícita, é mais elegante matematicamente que loess/lowess. O ajuste dos dois é muito semelhante para o mesmo número de graus de liberdade. Pode-se ajustar essas funções para diversos preditores. Existe uma forma mais complexa de spline mais complexo para splines (thin plate splines) que pode ser usada em modelos GAM. Ambas as funções podem também ser utilizadas no espaço. plot(lepto$week, lepto$cases, ylab=&quot;Casos Leptospirose&quot;, xlab=&quot;Semana&quot;, main = &quot;spline(.) -- 3 methods&quot;) lines(spline(lepto$week, lepto$cases, n=10 ), col = 2) lines(spline(lepto$week, lepto$cases, n=10, method = &quot;natural&quot;), col = 3) lines(spline(lepto$week, lepto$cases, n=10, method = &quot;periodic&quot;), col = 4) legend(&quot;topright&quot;,c(&quot;Defaut&quot;,&quot;Natural&quot;,&quot;Periódico&quot;),col=c(2,3,4), lty=c(1,1,1),title=&quot;Janela&quot;,bty=&quot;n&quot;) lepto.spl &lt;- smooth.spline(lepto$week, lepto$cases) lepto.spl.cv &lt;- smooth.spline(lepto$week, lepto$cases, cv =T) plot(lepto$week, lepto$cases, cex=.6, col=&quot;darkgray&quot;, ylab=&quot;Casos Leptospirose&quot;, xlab=&quot;Semana&quot;) lines(lepto.spl, col=1) lines(lepto.spl.cv, col=5) lines(smooth.spline(lepto$week, lepto$cases, df=10),col=3) lines(smooth.spline(lepto$week, lepto$cases, df=50),col=4) lines(smooth.spline(lepto$week, lepto$cases, df=2),col=2) legend(&quot;topright&quot;,c(&quot;Sem CV&quot;,&quot;Com CV&quot;,&quot;df=10&quot;, &quot;df=50&quot;, &quot;df=2&quot;),col=c(1,5,3,4,2), lty=c(1,1,1),title=&quot;Janela&quot;,bty=&quot;n&quot;) 4.8 Exercícios Propostos Seja \\(Z_t\\) (temperaturaNY.csv) uma série temporal referente às médias anuais das temperaturas na cidade de Nova York durante os anos de 1912 e 1971. Utilize e discuta alguns métodos de transformação e/ou suavização para descrever a série. Faça o mesmo com a série de dengue nas Filipinas (denguecases2.csv) Verifique as séries com atenção e veja como será a melhor maneira de ler e transformar o dado em ST. Lembre-se que no windows você talvez precise precisar rodar o código: options(url.method=&quot;libcurl&quot;) scan.win &lt;- function(x) {scan(url(x,method = &#39;libcurl&#39;))} 4.9 Bibliografia sugerida Faraway, J.J. Extending the Linear Model with R. Chapman &amp; Hall/CRC Texts in Statistical Science Series, 2006. Hastie, T.; Tibshirani, R. Generalised Additive Models. Chapman &amp; Hall, 1990. Wood, S.N. Generalized Additive Models: An Introduction with R. Chapman &amp; Hall/CRC Texts in Statistical Science Series, 2006. Venables, W.N. &amp; Ripley, B.D. Modern Applied Statistics with S. (MASS) Fourth Edition 2002 "],["modelagem-em-séries-temporais.html", " 5 Modelagem em Séries Temporais 5.1 O que são os Modelos Box &amp; Jenkins 5.2 Alguns processos estocásticos 5.3 Modelo ARIMA 5.4 Modelos ARIMA sazonais (SARIMA) - \\(ARIMA(p,d,q)(P,D,Q)_m\\) 5.5 Função de Autocorrelação Parcial (FACP) - (Partial Autocorrelation Function - PACF) 5.6 Processo de Modelagem 5.7 Processo de Identificação 5.8 Métricas para avaliar a qualidade do ajuste 5.9 Análise de Resíduos 5.10 Ajuste manual de modelo ARIMA 5.11 Ajuste automático de modelos ARIMA 5.12 Modelos de Previsão 5.13 Correlação Cruzada (Cross-Correlation) 5.14 GAM (Generalized Additive Models) 5.15 Exercícios Propostos 5.16 Bibliografia sugerida", " 5 Modelagem em Séries Temporais 5.1 O que são os Modelos Box &amp; Jenkins A abordagem de Box-Jenkins para a modelagem dos processos ARIMA foi descrita num livro publicado por George Box e Gwilym Jenkins em 1970. BOX, G.E.P. and G.M. JENKINS (1970) Time series analysis: Forecasting and control, San Francisco: Holden-Day. o método criado por Box &amp; Jenkins envolve a identificação de um processo ARIMA (Modelos autorregressivos, integrados e de médias móveis) adequado, ajustando-o aos dados e, uma vez ajustados permite também utilizar esses modelos para a descrição e/ou previsão (forecast). Uma das características atraentes da abordagem Box-Jenkins é que os processos ARIMA são uma classe muito rica de modelos e geralmente é possível encontrar um modelo que forneça uma descrição adequada dos dados. Ajustam simultaneamente tendência, sazonalidade, ciclicidade e estrutura de dependência serial. A dependência serial é a influência que um dado evento no tempo recebe de pontos anteriores. O processo de modelagem B&amp;J é feito em um ciclo iterativo de 3 estágios (repetido até o ajuste do modelo mais adequado): Identificação - análise exploratória, baseada em gráficos dos dados brutos, autocorrelação, autocorrelação parcial, buscando identificar o tipo de modelo + adequado; Estimação - estimativa de termos e parâmetros e seleção do “melhor modelo”; Diagnóstico - critérios de ajuste, parcimônia. 5.2 Alguns processos estocásticos Processo aleatório (ruido branco): sequência de variáveis aleatórias (\\(a_t\\)) que são mutuamente independentes e identicamente distribuídas. Possui média e variância constantes e os coeficientes de autocorrelação são iguais a: \\[ \\rho_{h} = \\left\\{ \\begin{array}{rc} 1, &amp;\\mbox{se} \\quad h = 0, \\\\ 0 , &amp;\\mbox{se} \\quad h = \\pm 1, \\pm 2, ... \\end{array}\\right.\\] Passeio aleatório (random walk): Denomina-se passeio aleatório quando a variável aleatória \\(Z_t\\) é igual à \\(Z_{t-1}\\) mais um erro aleatório \\(\\rightarrow\\) \\(Z_t = Z_{t-1} + a_t\\). Quando \\(t = 0 \\rightarrow Z_1 = a_1\\), logo \\[Z_t = \\sum_{t}^{i=1} a_i\\] 5.3 Modelo ARIMA Na análise de séries temporais, um Modelo Autorregressivo Integrado de Médias Móveis (Autoregressive Integrated Moving Average ou ARIMA, na sigla em inglês) é uma generalização de um Modelo Autorregressivo de Médias Móveis (ARMA). Ambos os modelos são ajustados aos dados da série temporal para entender melhor os dados ou para prever pontos futuros na série. Modelos ARIMA são aplicados em alguns casos em que os dados mostram evidências de não estacionariedade, em que um passo inicial de diferenciação (correspondente à parte “integrada” do modelo) pode ser aplicado uma ou mais vezes para eliminar a não estacionariedade. Temos então: AR (Autorregressivo): avalia a relação entre os períodos (lags) através da autocorrelação, ou seja, indica que a variável de interesse é “regressada” em seus próprios valores defasados, isto é, anteriores. O objetivo de desse modelo e extrair essa influência. I (Integrated): Aplica a diferenciação, se necessária, ou seja, indica que os valores de dados foram substituídos com a diferença entre seus valores. E os valores anteriores e este processo diferenciador pode ter sido realizado mais de uma vez. MA (Moving Average): Indica que o erro de regressão é na verdade uma combinação linear dos termos de erro, cujos valores ocorreram contemporaneamente e em vários momentos no passado, ou seja, avalia os erros entre períodos e extrai estes erros (não tem relação com MA usados para suavização da ST). p é a ordem (número de defasagens) do modelo autorregressivo; d é o grau de diferenciação (o número de vezes em que os dados tiveram valores passados subtraídos); q é a ordem do modelo de média móvel. Exemplos: Parâmetro Descrição \\(p = 1\\) Significa que uma determinada observação pode ser explicada pela observação prévia + erro \\(p = 2\\) Significa que uma determinada observação pode ser explicada por duas observações prévias + erro \\(d = 0\\) Significa que não é aplicada a diferenciação \\(d = 1\\) Significa que será aplicada diferenciação de primeira ordem \\(d = 2\\) Significa que será aplicada diferenciação de segunda ordem \\(q = 1\\) Significa que uma determinada observação pode ser explicada pelo erro da observação prévia \\(q = 2\\) Significa que uma determinada observação pode ser explicada pelo erro de duas observações prévias ARIMA Descrição AR(1) ou ARIMA(1,0,0) Apenas elemento autorregressivo , de \\(1^{a}\\) ordem AR(2) ou ARIMA(2,0,0) Apenas elemento autorregressivo , de \\(2^{a}\\) ordem MA(1) ou ARIMA(0,0,1) Apenas Média Móvel ARMA(1,1) Autorregressão e média móvel de \\(1^{a}\\) ordem 5.3.1 Modelo Autorregressivo de ordem p - AR(p) ou ARIMA(p,0,0) Supondo que a variável aleatória \\(Z_t\\) é linearmente correlacionada com seus próprios valores defasados, este é um modelo autorregressivo geral de ordem p. \\[Z_t = c + \\phi_1 Z_{t-1} + \\phi_2 Z_{t-2} + ... + \\phi_p Z_{t-p} + a_t\\] , sendo \\(t=1,2,...,p\\) O objetivo é estimar: a constante c - média do processo ou intercepto a ordem p do modelo - até onde vai a dependência os parâmetros \\(\\phi\\) de cada termo - peso de cada ponto passado na determinação do ponto t Para estimar os parâmetros \\(\\phi\\) de um AR, a estacionariedade de \\(1^a\\) e \\(2^a\\) ordens são fundamentais !!! Processo Modelo AR(1) \\[Z_t = c + \\phi_1 Z_{t-1} + a_t\\] AR(2) \\[Z_t = c + \\phi_1 Z_{t-1} + \\phi_2 Z_{t-2} + a_t\\] \\(\\dots\\) \\(\\dots\\) AR(p) \\[Z_t = c + \\phi_1 Z_{t-1} + \\phi_2 Z_{t-2} + ... + \\phi_p Z_{t-p} + a_t\\] 5.3.2 Condições de estacionariedade Uma série é estacionária quando suas propriedades não variam ao longo do tempo. Em um processo AR, a estacionariedade se reflete na estimação dos parâmetros: No caso AR(1) basta que \\(|\\phi_1| &lt; 1\\) para que o processo seja estacionário. No caso AR(2): \\(|\\phi_2|&lt; 1\\) \\(\\phi_2 + \\phi_1 &lt; 1\\) \\(\\phi_2 - \\phi_1 &lt; 1\\) 5.3.3 Modelo de Médias Móveis de ordem q - MA(q) ou ARIMA(0,0,q) Independente do processo autorregressivo, cada elemento da série pode também ser afetado pelo erro passado - processo “Médias Móveis”. Neste caso, o valor de \\(Z_t\\) depende de valores do componente aleatório em pontos anteriores (usa-se a denominação choque aleatório). \\[Z_t = C + a_t - \\theta_1 a_{t-1} - \\theta_2 a_{t-2} - ... - \\theta_p a_{t-q}\\] Por convenção os termos em a são escritos com sinais negativos Cada observação é a soma de um componente aleatório \\(a_t\\) e uma combinação dos componentes aleatórios anteriores. O modelo pode ser escrito baseado nas defasagens (informações passadas) do ruído branco Processo Modelo MA(1) \\[Z_t = c + a_t - \\theta_1 a_{t-1}\\] MA(2) \\[Z_t = c + a_t - \\theta_1 a_{t-1} - \\theta_2 a_{t-2}\\] \\(\\dots\\) \\(\\dots\\) MA(q) \\[Z_t = c + a_t - \\theta_1 a_{t-1} - \\theta_2 a_{t-2} - ... - \\theta_p a_{t-q} + a_t\\] 5.3.4 Condições de invertibilidade No modelo MA não há restrição sobre os \\(\\theta\\)’s para que o processo seja estacionário, mas é necessário garantir a invertibilidade. Existe uma dualidade entre processos médias móveis e autorregressivo, onde a equação de MA pode ser reescrita na forma AR (de ordem infinita). Se isso for possível, podemos dizer que o processo é invertível, ou seja, se puder utilizar um AR(p) para explicar um MA(q). Mas, para isso algumas condições devem ser satisfeitas: No caso MA(1) basta que \\(|\\theta| &lt; 1\\) para que o processo é invertível. No caso MA(2): \\(|\\theta_2|&lt; 1\\) \\(\\theta_2 + \\theta_1 &lt; 1\\) \\(\\theta_2 - \\theta_1 &lt; 1\\) 5.3.5 Modelo Autorregressivo de Médias Móveis de ordem p e q - ARMA(p,q) ou ARIMA(p,0,q) A importância de um modelo ARMA está no fato de poder descrever uma série estacionária por um modelo que envolve menos parâmetros que um MA puro ou um AR puro. \\[Z_t = c + \\phi_1 Z_{t-1} + \\phi_2 Z_{t-2} + ... + \\phi_p Z_{t-p} + a_t - \\theta_1 a_{t-1} - \\theta_2 a_{t-2} - ... - \\theta_p a_{t-q}\\] Cada observação é definida por combinação linear de observações anteriores e combinação de componentes aleatórios anteriores. Neste modelo misto, as duas condições - estacionariedade e invertibilidade - são necessárias Processo Modelo ARMA(1,1) \\[Z_t = c + \\phi_1 Z_{t-1} + a_t - \\theta_1 a_{t-1}\\] ARMA(2,2) \\[Z_t = c + \\phi_1 Z_{t-1} + \\phi_2 Z_{t-2} + a_t - \\theta_1 a_{t-1} - \\theta_2 a_{t-2}\\] \\(\\dots\\) \\(\\dots\\) ARMA(p,q) \\[Z_t = c + \\phi_1 Z_{t-1} + \\phi_2 Z_{t-2} + ... + \\phi_p Z_{t-p} + a_t - \\theta_1 a_{t-1} - \\theta_2 a_{t-2} - ... - \\theta_p a_{t-q}\\] No caso ARMA(1,1), o processo será estacionário se \\(|\\phi_1| &lt; 1\\) e \\(|\\theta_1| &lt; 1\\), respectivamente. 5.3.6 Modelo Autorregressivo Integrado de Médias Móveis de ordem p, d e q - ARIMA(p,d,q) Neste modelo se utiliza o método de diferenças para obter a estacionariedade da série. Também chamado de operador de deslocamento (backshift) \\[W_t = \\bigtriangledown Z_t = (1-B)Z_t = Z_t - Z_{t-1}\\] O modelo então passa a ser: \\[W_t = \\phi_1 W_{t-1} + ... + \\phi_p W_{t-p} + a_t - \\theta_1 a_{t-1} - ... - \\theta_q a_{t-q}\\] \\[\\phi(B)W_t = \\theta(B)a_t\\] \\[\\phi(B)(1-B)^d Z_t = \\theta(B)a_t\\] Assim, se a série for estacionária, podemos representá-la por um modelo ARMA(p,q). A figura abaixo mostra a série não estacionária antes e após diferenciação - \\(d(1)\\) A figura abaixo mostra a ACF antes e após a diferenciação: 5.3.7 Resumo - Modelos ARIMA não sazonais Resumindo, os modelos ARIMA não sazonais são geralmente denotados como ARIMA(p,d,q), em que os parâmetros p,d,q são números inteiros não negativos. Robusto: Pode ser usado em praticamente qualquer tipo de ST Dados estáveis, com poucos outliers Requer dados estacionários: pode ser transformada usando diferenciação: remove tendências Subtrai a observação do período atual do período anterior A diferenciação pode ser feita 1x: diferenciação de primeira ordem Ou pode ser necessário uma segunda vez: diferenciação de segunda ordem (mais raro) 5.4 Modelos ARIMA sazonais (SARIMA) - \\(ARIMA(p,d,q)(P,D,Q)_m\\) Em epidemiologia é comum observar sazonalidadenos dados. Ou seja, considerando medidas mensais, pode-se esperar que a série dependa também dos termos \\(Z_{t-12}\\) e talvez \\(Z_{t-24}\\). \\[\\phi(B) \\Phi(B^s)\\bigtriangledown_{s}^{D} \\bigtriangledown^{d}Z_t = C + \\theta(B) \\Theta(B^s) a_t\\] \\(\\phi(B) \\Phi(B^s)\\bigtriangledown_{s}^{D} \\bigtriangledown^{d}Z_t\\) \\(C + \\theta(B) \\Theta(B^s) a_t\\) AR(p) backshift x AR(P) sazonal backshift sazonal x diferenciação sazonal x diferenciação x tendência \\(Z_t\\) Média do processo + MA(q) backshift x MA(Q) sazonal backshift sazonal x erro aleatório São geralmente denotados como \\(ARIMA(p,d,q)(P,D,Q)_{m}\\), em que: m se refere ao número de períodos em cada temporada; P, D e Q se referem aos termos de autorregressão, diferenciação e média móvel para a parte sazonal do modelo ARIMA. 5.5 Função de Autocorrelação Parcial (FACP) - (Partial Autocorrelation Function - PACF) A correlação medida diretamente em \\(t-1\\), \\(t-2\\) até \\(t-p\\) é a função de autocorrelação. Uma outra ferramenta utilizada no processo de identificação do modelo é a Função de Autocorrelação Parcial (FACP). Esta medida corresponde a correlação de \\(Z_t\\) e \\(Z_{t-h}\\) removendo o efeito dos pontos intermediários \\(Z_{t-1}, Z_{t-2}, \\dots , Z_{t-h+1}\\) e é denotada por \\(\\rho_{h}\\). Ou seja, PACF é a correlação da série temporal com um atraso de si mesmo porém com a dependência linear de todos os desfasamentos entre eles removidos. \\[\\rho_{kk} = Corr(X_t, X_{t-l}|X_{t-1}, X_{t-2},\\dots,X_{t-h+1})\\] Segue abaixo um exemplo um exemplo de ACF, com já vimos anteriormente, e do PACF. Observe que há duas linhas horizontais que representam os limites do teste de significância sendo que valores acima ou abaixo da linha são estatisticamente significantes. No \\(lag = 1\\), a ACF e a PACF são iguais. Na PACF somente existe correlação até o lag igual a ordem do modelo AR - ex: modelo de ordem 3 somente apresenta valores de PACF até o \\(3^o\\) lag. As formas gráficas do ACF e PACF servem para definir valores de p e q. Olhando para os correlogramas, podemos determinar que tipo de modelo selecionar e quais serão os valores de p, d e q. Modelo Padrão do ACF Padrão do PACF AR(p) Decaimento exponencial ou padrão de onda senoidal amortecida ou ambos Picos significantes através de primeiros lags MA(q) Picos significantes através de primeiros lags Decaimento exponencial ou padrão em forma de senoides ARMA(1,1) Decaimento exponencial a partir do lag 1 Decaimento exponencial a partir do lag 1 ARMA(p,q) Decaimento exponencial Decaimento exponencial 5.6 Processo de Modelagem Para a construção do modelo podemos seguir o seguinte roteiro no qual a escolha da estrutura do modelo é baseado nos próprios dados: Identifica-se um modelo com base na análise de autocorrelações, autocorrelações parciais e outros critérios; Estima-se os parâmetros do modelo identificado; Verifica-se se o modelo ajustado é adequado aos dados através de uma análise de resíduos. Caso o modelo não seja adequado o roteiro é repetido, voltando à fase de identificação do modelo. Como definir valores de p,d e q ? p: ordem da parte autoregressiva - PACF d: grau de diferenciação – Teste de Estacionariedade q: ordem da média móvel - ACF 5.7 Processo de Identificação Esse processo pode ser extremamente difícil, mesmo para experientes. E nem sempre o modelo mais sugestivo é o melhor. Existem vários critérios para identificação de um modelo, por isso, é possível identificar modelos diferentes dependendo do critério que foi escolhido para identificação. Testar todas as combinações possíveis dos parâmetros \\(p,d,q\\) do modelo ARIMA seria uma boa ideia, mas isso pode ser um pouco demorado se for feito de forma manual. 5.7.1 Simulando os dados das ST com estruturas ARIMA Simulando um processo AR(1) # Simulando 100 observações através de um processo AR(1) com média 30 ar.sim&lt;-arima.sim(model=list(ar=.9),n=200, mean = 30) # Construindo o gráfico de ST ts.plot(ar.sim) # ACF e PACF par(mfrow=c(1,2)) ar.acf &lt;- acf(ar.sim,type=&quot;correlation&quot;,plot=T) ar.pacf &lt;- acf(ar.sim,type=&quot;partial&quot;,plot=T) plot(ar.acf) plot(ar.pacf) Simulando um processo AR(2) # Simulando 100 observações através de um processo AR(2) com média 30 ar.sim &lt;- arima.sim(model=list(ar=c(.9,-.2)),n=200, mean = 30) # Construindo o gráfico de ST ts.plot(ar.sim) # ACF e PACF par(mfrow=c(1,2)) ar.acf &lt;- acf(ar.sim,type=&quot;correlation&quot;,plot=T) ar.pacf &lt;- acf(ar.sim,type=&quot;partial&quot;,plot=T) plot(ar.acf) plot(ar.pacf) Simulando um processo MA(2) # Simulando 200 observações através de um processo MA(2) com média 30 ma.sim &lt;- arima.sim(model=list(ma=c(-.7,.1)),n=200, mean = 30) # Construindo o gráfico de ST ts.plot(ma.sim) # ACF e PACF par(mfrow=c(1,2)) ma.acf &lt;- acf(ma.sim,type=&quot;correlation&quot;,plot=T) ma.pacf &lt;- acf(ma.sim,type=&quot;partial&quot;,plot=T) plot(ma.acf) plot(ma.pacf) Simulando um processo ARMA(2,2) # Simulando 200 observações através de um processo ARMA(2,2) com média 30 arma.sim &lt;-arima.sim(model=list(ar=c(.9,-.2),ma=c(-.7,.1)),n=200, mean = 30) # Construindo o gráfico de ST ts.plot(arma.sim) # ACF e PACF par(mfrow=c(1,2)) arma.acf &lt;- acf(arma.sim,type=&quot;correlation&quot;,plot=T) arma.pacf &lt;- acf(arma.sim,type=&quot;partial&quot;,plot=T) plot(arma.acf) plot(arma.pacf) 5.8 Métricas para avaliar a qualidade do ajuste Para determinar a ordem de um modelo ARIMA não sazonal, um critério útil é o critério de informação de Akaike (AIC). \\[AIC = - 2log(L) + 2(p+q+k+1)\\] em que L é verossimilhança dos dados, p é a ordem da parte autoregressiva e q é a ordem da parte de média móvel. O parâmetro k neste critério é definido como o número de parâmetros no modelo sendo ajustado aos dados. O AIC corrigido para modelos ARIMA (AICc) pode ser escrito como: \\[AICc = AIC + \\dfrac{2(p+q+k+1)(p+q+k+2)}{T-p-q-k-2}\\] O critério de informação bayesiano (BIC) pode ser escrito como: \\[BIC = AIC + (log(n) - 2) (p+q+k+1)\\] O objetivo é o minimizar os valores de AIC, AICc e BIC para um bom modelo. Quanto menor o valor de um destes critérios para uma gama de modelos investigados, melhor o modelo se adequará aos dados. O AICc pode ser usado apenas para comparar modelos ARIMA com as mesmas ordens de diferenciação. Para modelos ARIMA como ordens distintas de diferenciação, a raiz do erro quadrático médio pode ser usada para comparação de modelos. A abordagem do BIC penaliza mais intensamente os modelos por levar em consideração o \\(n\\). 5.9 Análise de Resíduos Se o modelo está correto, as nossas suposições iniciais feitas para os resíduos devem ser satisfeitas, isto é, \\(a_t \\sim N(0, \\sigma^{2}_{a})\\) e independentes. Assim, a análise de resíduos é feita da seguinte forma: Faz-se um gráfico da série \\(a_t\\) e observa-se a sua estacionariedade e se sua média é igual a zero (aproximadamente). Se a série \\(a_t\\) for estacionária, calcula-se suas funções de autocorrelação e autocorrelação parcial amostral; Se as funções em (2) indicarem que o processo gerador de \\(a_t\\) é um ruído branco, o modelo escolhido para \\(Y_t\\) poderá ser ser considerado adequado. Senão, podemos utilizar a análise dos resíduos para identificar outro modelo para a série. Lembrando que o processo \\(a_t\\) é um ruído branco se: \\(E(a_t) = 0\\), \\(a_t \\sim N(0, \\sigma^2_a)\\), \\(Cov(a_t, a_{t-h}) = 0\\), \\(\\forall h \\neq 0\\) (Não correlacionados) 5.10 Ajuste manual de modelo ARIMA library(forecast) ggtsdisplay(ldeaths) modelo0 &lt;- Arima(ldeaths,order = c(1,0,0),seasonal = c(1,1,1)) checkresiduals(modelo0) Ljung-Box test data: Residuals from ARIMA(1,0,0)(1,1,1)[12] Q* = 11, df = 11, p-value = 0.5 Model df: 3. Total lags used: 14 tsdiag(modelo0) plot(ldeaths) lines(fitted(modelo0),col=&quot;red&quot;) 5.11 Ajuste automático de modelos ARIMA O pacote forecast de autoria Rob Hyndman e colaboradores possui diversas funções para visualização, análise e predições de séries temporais. Entre elas existe uma função que faz ajustes automáticos para modelos ARIMA. Essa função se chama auto.arima(). Testa diferentes combinações de \\(p\\), \\(d\\) e \\(q\\) buscando o melhor ajuste Extremamente flexível Mesmo intuindo um modelo, você pode usá-la para confirmar sua parametrização Alguns parâmetros importantes da função auto.arima(): stationary - Se TRUE, restringe sua busca por modelos estacionários. seasonal - Se FALSE, restringe sua busca por modelos não sazonais. stepwise - Se TRUE, utilizará o métodos de stepwise de seleção (mais rápido). Caso contrário, irá buscar todas as combinações. O método de seleção non-stepwise pode ser muito lento, especialmente para os modelos sazonais. trace - Se TRUE, a lista de modelos ARIMA considerados será reportada. approximation - Se TRUE, o processo de estimação é feito através das somas dos quadrados condicionais e os critérios de informação utilizados para a seleção de modelos são aproximados. O modelo final ainda é calculado usando estimativa de máxima verossimilhança. A aproximação deve ser usada para séries temporais longas ou um período sazonal elevado para evitar tempos de computação excessivos. # Utilizando trace = T, será possível verificar todo o processo de criação e teste dos modelos modelo1 &lt;- auto.arima(ldeaths, trace = F, allowdrift=F) # Neste modelo, será feito uma busca maior para uma solução &quot;mais otimizada&quot; modelo2 &lt;- auto.arima(ldeaths, trace = F, stepwise = F, approximation = F,parallel = TRUE) Vamos verificar cada um dos modelos obtidos: modelo1 Series: ldeaths ARIMA(0,0,1)(2,1,0)[12] Coefficients: ma1 sar1 sar2 0.427 -0.860 -0.361 s.e. 0.138 0.143 0.145 sigma^2 estimated as 70422: log likelihood=-423.3 AIC=854.6 AICc=855.3 BIC=863 # library(texreg) # texreg::htmlreg(modelo1, star.symbol = &quot;\\\\*&quot;, center = TRUE, doctype = FALSE, html.tag = TRUE, head.tag = FALSE, body.tag = FALSE) pander(modelo1) Call: auto.arima(y = ldeaths, trace = F, allowdrift = F, x = structure(list(x = structure(c(3035, 2552, 2704, 2554, 2014, 1655, 1721, 1524, 1596, 2074, 2199, 2512, 2933, 2889, 2938, 2497, 1870, 1726, 1607, 1545, 1396, 1787, 2076, 2837, 2787, 3891, 3179, 2011, 1636, 1580, 1489, 1300, 1356, 1653, 2013, 2823, 3102, 2294, 2385, 2444, 1748, 1554, 1498, 1361, 1346, 1564, 1640, 2293, 2815, 3137, 2679, 1969, 1870, 1633, 1529, 1366, 1357, 1570, 1535, 2491, 3084, 2605, 2573, 2143, 1693, 1504, 1461, 1354, 1333, 1492, 1781, 1915), .Tsp = c(1974, 1979.91666666667, 12), class = “ts”)), class = “data.frame”, row.names = c(NA, -72L))) Coefficients   ma1 sar1 sar2 0.4269 -0.8595 -0.3613 s.e. 0.1385 0.1426 0.1452 sigma^2 estimated as 70422: log likelihood = -423.3, aic = 854.6 tsdiag(modelo1) # texreg::htmlreg(modelo2, star.symbol = &quot;\\\\*&quot;, center = TRUE, doctype = FALSE, html.tag = TRUE, head.tag = FALSE, body.tag = FALSE) modelo2 Series: ldeaths ARIMA(2,0,0)(0,1,2)[12] with drift Coefficients: ar1 ar2 sma1 sma2 drift 0.255 -0.339 -1.163 0.357 -5.334 s.e. 0.134 0.140 0.362 0.205 0.905 sigma^2 estimated as 49449: log likelihood=-416.4 AIC=844.8 AICc=846.4 BIC=857.4 pander(modelo2) Call: auto.arima(y = ldeaths, stepwise = F, trace = F, approximation = F, parallel = TRUE, x = structure(list(x = structure(c(3035, 2552, 2704, 2554, 2014, 1655, 1721, 1524, 1596, 2074, 2199, 2512, 2933, 2889, 2938, 2497, 1870, 1726, 1607, 1545, 1396, 1787, 2076, 2837, 2787, 3891, 3179, 2011, 1636, 1580, 1489, 1300, 1356, 1653, 2013, 2823, 3102, 2294, 2385, 2444, 1748, 1554, 1498, 1361, 1346, 1564, 1640, 2293, 2815, 3137, 2679, 1969, 1870, 1633, 1529, 1366, 1357, 1570, 1535, 2491, 3084, 2605, 2573, 2143, 1693, 1504, 1461, 1354, 1333, 1492, 1781, 1915), .Tsp = c(1974, 1979.91666666667, 12), class = “ts”)), class = “data.frame”, row.names = c(NA, -72L))) Coefficients   ar1 ar2 sma1 sma2 drift 0.2555 -0.3389 -1.163 0.3566 -5.334 s.e. 0.1341 0.1402 0.3624 0.2048 0.9049 sigma^2 estimated as 49449: log likelihood = -416.4, aic = 844.8 tsdiag(modelo2) Comparando os ajustes dos modelos plot(ldeaths) lines(fitted(modelo0),col=&quot;red&quot;) lines(fitted(modelo1),col=&quot;blue&quot;) lines(fitted(modelo2),col=&quot;darkgreen&quot;) 5.12 Modelos de Previsão Uma vez ajustado um modelo ARIMA a uma série temporal é possível fazer uma predição de \\(K\\) passos a frente, permitindo obter a previsão da série no instante \\(t + k\\), denotada por $_{t+k} $. Podemos obter também os limites de confiança. Os modelos de previsão são uma área importante e um campo muito ativo de desenvolvimento de métodos estatísticos e computacionais. Aqui vamos somente apresentar um exemplo utilizando um dos modelos já ajustados para a serie ldeaths. Uma maneira simples de obter o valor predito é usando a função predict() predict(modelo1, n.ahead = 12) o pacote forecast possui funções para facilitar a predição e visualização. Veja na função abaixo que o modelo já retorna não só o valor predito mas também os limites superior e inferior para os níveis de confiança 80 e 95. forecast(modelo1,h=12) Ele também facilita a confecção de gráficos plot(pred) # a função autoplot produz no formato ggplot Para saber mais sobre séries temporais e previsões recomendamos o excelente livro online Forecasting: Principles and Practice Rob J Hyndman and George Athanasopoulos 5.13 Correlação Cruzada (Cross-Correlation) Vamos considerar a situação em que temos duas ou mais séries temporais e queremos explorar as relações entre elas. A ideia seria modelar a série \\(Z_{t}^{1}\\) usando os pontos anteriores de \\(Z_{t}^{2}\\). A correlação cruzada descreve o grau de correlação entre duas séries. A correlação cruzada é usada para determinar quando uma mudança em um série pode potencializar a causa da mudança na outra série. \\[Z_{t} = v(B) X_t + N_t\\] para a qual: \\(v(B)\\) é a função de transferência (filtro) \\(Z_t,X_t\\) são séries estacionarias \\(N_t\\) é um ruído independente de \\(X_t\\) Vamos analisar: O atraso de uma série em relação a outra O feedback Correlação dos resíduos, removida a estrutura temporal A título de demonstração da função de correlação cruzada (Cross-correlation Function), vamos usar como exemplo dados de temperatura da área central do Reino Unido, obtidos do UK Met Office e vamos correlacionar com a série ldeaths . uktemp &lt;- read.table(&#39;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/dados/UKtemp.tsv&#39;) uktemp &lt;- ts(as.vector(t(uktemp[,2:13])),start = c(1970,1),frequency = 12) uktemp.ts &lt;- window(uktemp,start=c(1974,1),end=c(1979,12)) fcc &lt;- ccf(uktemp.ts,ldeaths) cbind(fcc$lag,fcc$acf) -1.2500 -0.1859 -1.1667 -0.4816 -1.0833 -0.6586 -1.0000 -0.6518 -0.9167 -0.4912 -0.8333 -0.1953 -0.7500 0.1562 -0.6667 0.5214 -0.5833 0.7748 -0.5000 0.8002 -0.4167 0.5991 -0.3333 0.2354 -0.2500 -0.1907 -0.1667 -0.5479 -0.0833 -0.7891 0.0000 -0.8320 0.0833 -0.6264 0.1667 -0.2453 0.2500 0.1974 0.3333 0.5818 0.4167 0.8115 0.5000 0.8207 0.5833 0.6039 0.6667 0.2426 0.7500 -0.1756 0.8333 -0.5441 0.9167 -0.7285 1.0000 -0.7110 1.0833 -0.5332 1.1667 -0.2181 1.2500 0.1562 max(abs(fcc$acf)) [1] 0.832 5.14 GAM (Generalized Additive Models) Um modelo aditivo generalizado (Hastie and Tibishirani, 1990) é um modelo linear generalizado com um preditor linear envolvendo a soma de funções suavizadas das covariáveis + os efeitos fixos das mesmas. \\[\\eta = \\sum X \\beta + f_1(x_{1i}) + f_2(x_{2i}) + \\ldots\\] Pode ser considerado uma extensão do GLM, onde o preditor linear \\(\\eta = E(Y_i)\\) não é limitado para a regressão linear, sendo \\(Y_i \\sim\\) alguma distribuição da família exponencial. \\(Y_i\\) é a variável resposta (desfecho) \\(X\\) é o vetor das variáveis explicativas (exposição) \\(\\beta\\) representa o vetor de parâmetros a serem estimados pelo modelo. O modelo inclui qualquer função das covariáveis independentes (\\(x_i\\)) $f(x) $ pode ser uma função não-paramétrica, cuja forma não é especificada a priori. Mas pode ser estimada através de curvas de alisamento (ex: kernel, loess, splines, etc.) A curva alisada permite descrever a forma e revelar possíveis não linearidades nas relações estudadas, uma vez que não apresenta a estrutura rígida de uma função paramétrica, como nos GLM’s. Quando usar? Quando o efeito da covariável muda dependendo do seu valor. 5.14.1 Tipos de splines Cubic regression spline – polinômios de grau 3 ajustados aos intervalos dos dados definidos pelos nós distribuı́dos regularmente em todo o escopo dos dados. A base é a soma de nós mais 2, que correspondem ao início e fim da curva. Os polinômios são unidos de forma a existir as 1 e 2 derivadas. Cyclic cubic regression spline – força a função a ter o mesmo valor e mesmas derivadas no início e final. Interessante para séries temporais com sazonalidade. P-splines – Baseia-se na B-spline, na qual a função vai obrigatoriamente a zero em m+3 nós adjacentes. A p-spline se baseia nessa, porém aplica uma penalidade diferencial entre β’s adjacentes para controlar a “wiggliness”. Thin plate – menor erro quadrático, menor número de parâmetros considerado o estimador ótimo. Facilmente adaptável para duas/três dimensões. Tensor Product – Semelhante ao Thin Plate, mas permite escalas bs= Descrição Vantagens Desvantagens “tp” Thin Plate Suaviza múltiplas covariáveis. Não se altera com a rotação. Estimador ótimo. Computacionalmente custoso. Não é invariante quanto à escala. “cr” Cubic Regression Computacionalmente barato. Parâmetros interpretáveis diretamente. Só uma covariável. Baseado na escolha dos nós. Estimador não ótimo. “cc” Cyclic CRS Começo e fim = ’s Idem. “ps” P-splines Qualquer combinação de base e ordem. Nós em intervalos iguais. Penalidades difíceis de interpretar. Estimador não ótimo. 5.14.2 Por que não usar ? Os modelos estatísticos visam explicar os dados observados, não simplesmente reproduzi-lo \\(\\rightarrow\\) overfitting Modelos paramétricos em geral são melhores para estimar erros padrão ou intervalos de confiança Modelos paramétricos são mais eficientes, se corretamente especificados (menor número de observações) 5.14.3 GAM em Séries Temporais A idéia principal é modelar o efeito de covariáveis em alguns eventos de saúde ao longo do tempo Razões: Permitir a inclusão da dependência do tempo Relação não-linear Tendência e sazonalidade podem ser facilmente incorporadas Considerando a variável resposta uma contagem, as escolhas para as distribuições são: Poisson: \\(\\lambda\\) \\(=\\) valores esperados e \\(=\\) variância \\(\\rightarrow\\) superdispersão Quasipoisson: não é uma distribuição, mas uma maneira de relaxar suposição do modelo anterior e levar em consideração a superdispersão. (Não estima o AIC automaticamente). Negative Binomial: tem uma média \\(\\mu\\), um parâmetro de escala \\(\\theta\\) e a variância como a função \\(V(\\mu)=\\mu+\\mu^2/\\theta\\) Modelos com inflação zero: modelos de mistura que combinam uma massa pontual a zero com uma distribuição de contagem como Poisson, geométrica ou binomial negativa 5.14.4 Exemplo de modelo GAM aplicado a ST ldeaths Transforma o exemplo ldeaths de ts em data.frame preservando as estruturas temporais (tempo e mês) ldeaths.df &lt;- data.frame(tempo=time(ldeaths),obitos=ldeaths,mes=cycle(ldeaths)) ldeaths.df tempo obitos mes 1974 3035 1 1974 2552 2 1974 2704 3 1974 2554 4 1974 2014 5 1974 1655 6 Modelando como GAM: mod0 &lt;- gam ( obitos ~ s(tempo) + s(mes),data=ldeaths.df) mod0 Sumário do modelo A. parametric coefficients Estimate Std. Error t-value p-value (Intercept) 2056.6250 26.7125 76.9911 &lt; 0.0001 B. smooth terms edf Ref.df F-value p-value s(tempo) 1.0003 1.0007 14.4150 0.0003 s(mes) 5.7942 6.9532 59.0681 &lt; 0.0001 R-quadrado(ajustado) = 0.86 Deviance Explicada = 0.88 AIC = 995.27 Gráfico dos termos suaves: Análise de resíduos Vamos verificar se sobraram estruturas nos resíduos usando a ACF dos resíduos e o teste de Ljung-Box: acf(residuals(mod0)) pander(Box.test(residuals(mod0),type=&#39;Ljung-Box&#39;)) Box-Ljung test: residuals(mod0) Test statistic df P value 0.7716 1 0.3797 Como podemos observar a variável tempo que captura a tendência ficou completamente linear. Vamos agora usar a variavel tempo de forma linear no modelo. mod1 &lt;- gam ( obitos ~ tempo + s(mes),data=ldeaths.df) mod1 A. parametric coefficients Estimate Std. Error t-value p-value (Intercept) 119492.6570 30969.4892 3.8584 0.0003 tempo -59.4024 15.6652 -3.7920 0.0003 B. smooth terms edf Ref.df F-value p-value s(mes) 5.5691 6.7170 60.8243 &lt; 0.0001 R-quadrado(ajustado) = 0.86 Deviance Explicada =0.87 AIC = 994.67 acf(residuals(mod1)) Box-Ljung test: residuals(mod1) Test statistic df P value 0.7346 1 0.3914 5.14.5 Exemplo GAM: Casos de Leptospirose vs Clima Vamos utilizar uma a série temporal dos casos de leptospirose com as variáveis de esposição total de chuva e temperatura. \\[\\text{Lepto}(t) = \\text{rain}(t-?) + \\text{humidity}(t-?) + AR(t,t-1) + trend + seasonality + \\varepsilon\\] Tendência e Sazonalidade \\(\\to\\) função suavizadora Covariáveis \\(\\to\\) lag no tempo É possível incluir a variabilidade populacional em risco (offset) lepto &lt;- read.csv2(&quot;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/dados/leptoruido.csv&quot;, header=T) dia &lt;- read.table(&quot;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/dados/climadia.dat&quot;, header=T) library(lattice) library(car) library(sm) library(survival) library(mgcv) #XY condicionado xyplot(cases + totrain + tempmed ~ week, outer=TRUE, layout=c(1, 3), pch=1, type=&quot;l&quot;,ylab=&quot;&quot;, scales=list(x=list(relation=&#39;same&#39;), y=list(relation=&#39;free&#39;)), data=lepto) Modelando a Chuva como resposta e colocando a função suavizadora para capturar o efeito nas semanas epidemológicas xyplot(totrain ~ week, outer=TRUE, layout=c(1, 1), pch=1, type=&quot;l&quot;,ylab=&quot;Chuva&quot;, scales=list(x=list(relation=&#39;same&#39;), y=list(relation=&#39;free&#39;)), data=lepto) # Ajustando a chuva como resposta par(mfrow=c(2,2)) rain.tp.auto &lt;- gam(totrain ~ s(week,bs=&quot;tp&quot;), data=lepto ) plot(rain.tp.auto,main=paste(&#39;K = &#39;,rain.tp.auto$smooth[[1]]$bs.dim)) rain.tp.k1 &lt;- gam(totrain ~ s(week,bs=&quot;tp&quot;,k=1), data=lepto ) plot(rain.tp.k1,main = paste(&#39;K =&#39;,rain.tp.k1$smooth[[1]]$bs.dim)) rain.tp.k30 &lt;- gam(totrain ~ s(week,bs=&quot;tp&quot;,k=30), data=lepto ) plot(rain.tp.k30,main=paste(&#39;K =&#39;,rain.tp.k30$smooth[[1]]$bs.dim)) rain.ad &lt;- gam(totrain ~ s(week,bs=&quot;ad&quot;), data=lepto ) plot(rain.ad,main=paste(&#39;K(adaptável) =&#39;, rain.ad$smooth[[1]]$bs.dim)) # ThinPlate &lt;- predict(rain.tp) # P.spline &lt;- predict(rain.ps) # CubicRegression &lt;- predict(rain.cr) # CyclicCR &lt;- predict(rain.cc) # Adaptative &lt;- predict(rain.ad) Ajustando a série dos casos de leptospirose via distribuição Poisson: library(quantmod) # para utilizar a funcao Lag chuvl0 &lt;- gam(cases ~ s(totrain) ,family=poisson,data=subset(lepto, week&gt;5)) chuvl1 &lt;- gam(cases ~ s(Lag(totrain,1)),family=poisson,data=subset(lepto, week&gt;5)) chuvl2 &lt;- gam(cases ~ s(Lag(totrain,2)),family=poisson,data=subset(lepto, week&gt;5)) chuvl3 &lt;- gam(cases ~ s(Lag(totrain,3)),family=poisson,data=subset(lepto, week&gt;5)) chuvl4 &lt;- gam(cases ~ s(Lag(totrain,4)),family=poisson,data=subset(lepto, week&gt;5)) chuvl5 &lt;- gam(cases ~ s(Lag(totrain,5)),family=poisson,data=subset(lepto, week&gt;5)) AIC(chuvl0,chuvl1,chuvl2,chuvl3,chuvl4,chuvl5) Ajustando a série dos casos de leptospirose via distribuição Binomial Negativa chuvnb0 &lt;- gam(cases ~ s(Lag(totrain,0)),data=lepto, family=nb(), subset=week&gt;5) chuvnb1 &lt;- gam(cases ~ s(Lag(totrain,1)),data=lepto, family=nb(), subset=week&gt;5) chuvnb2 &lt;- gam(cases ~ s(Lag(totrain,2)),data=lepto, family=nb(), subset=week&gt;5) chuvnb3 &lt;- gam(cases ~ s(Lag(totrain,3)),data=lepto, family=nb(), subset=week&gt;5) chuvnb4 &lt;- gam(cases ~ s(Lag(totrain,4)),data=lepto, family=nb(), subset=week&gt;5) chuvnb5 &lt;- gam(cases ~ s(Lag(totrain,5)),data=lepto, family=nb(), subset=week&gt;5) chuvnb5$family$getTheta() [1] 0.4864 AIC(chuvnb0,chuvnb1,chuvnb2,chuvnb3,chuvnb4,chuvnb5) Comparando os AIC’s de ambos os modelos entre os lags plot(0:5,AIC(chuvl0,chuvl1,chuvl2,chuvl3,chuvl4,chuvl5)[,2], type=&quot;l&quot;,ylim=c(2090,2850), ylab=&quot;AIC&#39;s&quot;, xlab = &quot;Lags&quot;) lines(0:5,AIC(chuvnb0,chuvnb1,chuvnb2,chuvnb3,chuvnb4,chuvnb5)[,2], type=&quot;l&quot;,col=2) legend(&quot;right&quot;,c(&quot;Poisson&quot;,&quot;Bin. Neg.&quot;),col=1:2,fill=1:2) Verificando a distribuição da chuva entre todos os lags boxplot(lepto$totrain) par(mfrow=c(3,2),mai=c(0.05,0.5412 ,0.5412,0.05),mgp=c(2,1,0)) plot(chuvnb0,ylab=&quot;Lag=0&quot;) abline(h=0,lty=2,col=2) plot(chuvnb1,ylab=&quot;Lag=1&quot;) abline(h=0,lty=2,col=2) plot(chuvnb2,ylab=&quot;Lag=2&quot;) abline(h=0,lty=2,col=2) plot(chuvnb3,ylab=&quot;Lag=3&quot;) abline(h=0,lty=2,col=2) plot(chuvnb4,ylab=&quot;Lag=4&quot;) abline(h=0,lty=2,col=2) plot(chuvnb5,ylab=&quot;Lag=5&quot;) abline(h=0,lty=2,col=2) E agora? incluir humidade, temperatura, etc etc… 5.15 Exercícios Propostos Utilize o banco de dados do R chamado Seatbelts, que é baseado em uma série histórica que mostra os totais mensais dos condutores de automóveis na Grã-Bretanha mortos ou gravemente feridos, de 1969 a dezembro de 1984. O uso obrigatório dos cintos de segurança foi introduzido em 31 de janeiro de 1983. Variáveis Descrição DriversKilled Motoristas de carro mortos drivers Motoristas front Passageiros do banco da frente mortos ou gravemente feridos rear Passageiros do banco traseiro mortos ou gravemente feridos kms Distância percorrida PetroPrice Preço da gasolina VanKilled Número de condutores de van (veículo leve de mercadorias) law A lei estava em vigor naquele mês (1/0) Pede-se: Ajuste um modelo ARIMA com a variável de desfecho DriversKilled; Ajuste um modelo GAM utilizando a variável de desfecho DriversKilled e verifique quais variáveis estão mais associadas ao modelo. Dados climatológicos de temperaturas máxima, mínima e pluviosidade para as 10 áreas de planejamento (AP) da cidade do Rio de Janeiro de 2001 a 2016 estão disponíveis nos arquivos abaixo. Use a função read.csv2 para ler o dado. temperatura máxima temperatura mínima pluviosidade Escolha uma delas, descreva a série e tente modelar usando os modelos B&amp;J ou GAM. 5.15.1 Exercícios Resolvidos Acidentes de transito UK Dados Climaticos 5.16 Bibliografia sugerida Asteriou, D.; Hall, S.G. Applied econometrics. Macmillan International Higher Education, 2015. Brockwell, Peter J.; DAVIS, Richard A.; CALDER, Matthew V. Introduction to time series and forecasting. New York: springer, 2002. Harvey, A. C. and Durbin, J. The effects of seat belt legislation on British road casualties: A case study in structural time series modelling. Journal of the Royal Statistical Society series A, 149, 187–227. 1986. Hastie, T.; Tibshirani, R. Generalised Additive Models. Chapman &amp; Hall, 1990. Hyndman, R.J and Khandakar, Y. Automatic time series forecasting: The forecast package for R, Journal of Statistical Software, 26(3). 2008. Webster, C.E.J. Time series properties of econometric models and their implied ARIMA representation. 1983. Wood, S.N. Generalized Additive Models: An Introduction with R. Chapman &amp; Hall/CRC Texts in Statistical Science Series, 2006. "],["introdução-à-análise-estatística-espacial-padrão-de-pontos-i.html", " 6 Introdução à Análise Estatística Espacial &amp; Padrão de Pontos I", " 6 Introdução à Análise Estatística Espacial &amp; Padrão de Pontos I "],["análise-espacial-padrão-de-pontos-ii.html", " 7 Análise Espacial - Padrão de Pontos II", " 7 Análise Espacial - Padrão de Pontos II "],["análise-espacial-dados-de-área-i.html", " 8 Análise Espacial - Dados de Área I", " 8 Análise Espacial - Dados de Área I "],["dados-de-área-ii.html", " 9 Dados de Área II", " 9 Dados de Área II "],["análise-espacial-geoestatística.html", " 10 Análise Espacial - Geoestatística", " 10 Análise Espacial - Geoestatística "],["análise-espaço-temporal-instruções-e-dúvidas-para-o-trabalho-final.html", " 11 Análise Espaço-Temporal &amp; Instruções e Dúvidas para o Trabalho Final", " 11 Análise Espaço-Temporal &amp; Instruções e Dúvidas para o Trabalho Final "],["roteiro-para-a-execução-do-trabalho-final.html", " 12 Roteiro para a execução do trabalho final 12.1 Ficha de Avaliação 12.2 FIM", " 12 Roteiro para a execução do trabalho final 1- Este trabalho poderá ser feito de forma individual ou em dupla; 2- Este trabalho será dividido em duas etapas. A primeira etapa deverá ser baseada em uma análise do tipo Série Temporal (ST) e a segunda em uma Análise Espacial (AE). A primeira etapa irá valer 4,0 pontos e a segunda 6,0 pontos; 3- Em cada etapa poderá ser feita análises com tipos de dados diferentes, ou seja, com desfechos ou estudos distintos para cada tipo de análise; 4- Em ambas as etapas, o tema analisado deverá ser descrito sucintamente assim como as variáveis analisadas, sempre especificando a unidade espacial (ex: setor censitário, bairro, município, estado, etc.) e a temporal (ex: dia, semana, mês, ano, etc) que serão levadas em consideração. Caso os dados sejam os mesmos em ambas as etapas, tal descrição poderá ser feita apenas uma vez; 5- A primeira etapa deverá constar os seguintes procedimentos para as análises: Ler o banco de dados pretendido, transformar em formato de ST, decompor a ST e testar a presença dessas componentes. Opcionalmente ajustar os modelos , testar os pressupostos e interpretar o modelo. 6- A segunda etapa poderá ser feita utilizando os tipos de dados em padrão pontual ou em área. Nesta etapa deverá constar um dos seguintes procedimentos para as análises: 6.1 – Padrão Pontual Ler o banco de dados pretendido Transformar em formato espacial Explorar o Processo de primeira ordem (Ex: Testar CSR, Função Kernel) Explorar o Processo de segunda ordem (Ex: Função K, F, L) Opcional: Modelagem (Ex: GAM) OU 6.2 – Dados de Área Ler o arquivo vetorial (.shp) e/ou banco de dados pretendido criar Matriz de Vizinhança Análise exploratória Espacial (Mapas temáticos, autocorrelação espacial) Opcional: Modelagem (ex: SAR, CAR ou GWR) 7- Discutir os resultados em ambas as etapas. 8- Entregar um relatório escrito em PDF no formato de artigo com introdução, objetivos, metodologia, resultados e sua respectiva análise e uma breve discussão. 9- Não esquecer de compactar todos os scripts e dados em um unico arquivo com seu nome ou nome da dupla e data (por exemplo Laís_&amp;_Oswaldo_04Ago2021.ZIP). 10- O prazo FINAL para envio dos trabalhos é 06 de Agosto de 2021 11- Envio do trabalho devera ser feito usando o link abaixo! Clique aqui para enviar o arquivo final 12.0.1 Sugestões de locais para baixar os dados e os mapas SIDRA/IBGE TABNET-MS openDataSUS Brasil.IO 12.1 Ficha de Avaliação Para que possamos melhorar o curso gostaríamos muito de contar com a colaboração de vocês, para isso pedimos que preencham um formulário de avaliação do curso no google forms. O formulário pode ser preenchido de uma maneira anonima e conta com uma sessão de identificação , nome (opcional) se é aluno de mestrado ou doutorado e qual é sua área de formação básica. Em seguida pedimos que avaliem o curso em 4 módulos Estudos Ecológico Series temporais Analise exploratória espacial Modelagem espacial e ao final existe um campo livre onde você poderá fazer criticas, observações , sugestões etc… por favor preencha com atenção e envie somente uma vez, o formulário é anonimo não temos como identificar duplicidades! clique no link abaixo e acesse: Google Forms 12.2 FIM Parabéns você chegou ao final do Curso "],["anexo-i-roteiro-séries-temporais.html", "Anexo I - Roteiro séries temporais", " Anexo I - Roteiro séries temporais "],["anexo-ii-fazendo-mapas-com-ggplot.html", "Anexo II - Fazendo mapas com ggplot", " Anexo II - Fazendo mapas com ggplot "],["estudos-ecológicos-1.html", " 13 Estudos Ecológicos 13.1 O que são Estudos Ecológicos ? 13.2 Principais objetivos 13.3 Tipos de Variáveis Utilizadas 13.4 Tipos de Desenhos de Estudos Ecológicos 13.5 Aspectos históricos 13.6 Epidemiologia social 13.7 Árvores, Bosques ou as Florestas? 13.8 Falácia Ecológica ou viés de agregação 13.9 Problemas práticos 13.10 Vantagens 13.11 Desvantagens 13.12 Resumindo 13.13 Exercícios Propostos 13.14 Bibliografia sugerida", " 13 Estudos Ecológicos 13.1 O que são Estudos Ecológicos ? São estudos nos quais a unidade de análise (ou agregação) é uma população ou um grupo de pessoas, geralmente de uma área geográfica definida (ex: um país, um estado, uma cidade, etc.), em um determinado tempo definido. Definição Clássica: é um estudo observacional com a informação obtida e analisada no nível agregado. Geralmente são mais baratos e mais rápidos do que estudos envolvendo o indivíduo como unidade de análise. Procuram avaliar como os contextos (sociais, ambientais, etc) podem afetar a saúde de grupos populacionais. 13.2 Principais objetivos Gerar hipóteses etiológicas; Testar hipóteses etiológicas; Avaliar a efetividade de intervenções na população; Identificar áreas de risco. Exemplo 1: Em 1960, Friedman mostrou uma correlação positiva entre as taxas de mortalidade por doença coronariana (DC) e as vendas de cigarros per capita, em 44 estados americanos. Esta observação inicial contribuiu para a formulação da hipótese de que o tabagismo poderia causar doença coronariana Figura: Coronary heart disease mortality rates in the United States per capita cigarette sales in 1960, by state. (From FRIEDMAN GD, Cigarette smoking and geographic variation in coronary heart disease mortality in the United States. J. Chronic Dis. 20: 769, 1967) 13.3 Tipos de Variáveis Utilizadas Medidas Agregadas: Medidas agregadas por grupos. ex: incidência, prevalência, mortalidade, proporção de fumantes; Medidas Ambientais: Características físicas do contexto onde o grupo convive. ex: nível de poluição, precipitação; Medidas Globais: Atributos de grupos, organizações ou lugares, que não podem ser mensurados a nível individual. ex: IDH, densidade demográfica, existência de um tipo de sistema de saúde. Em uma análise ecológica, todas as variáveis são medidas agrupadas. Apenas se conhece a distribuição marginal de cada variável. Desfecho (Y) Fator em Estudo (X) Ocorreu Não ocorreu Total Exposto ? ? \\(E_1\\) Não Exposto ? ? \\(E_0\\) Total \\(D_1\\) \\(D_0\\) n 13.4 Tipos de Desenhos de Estudos Ecológicos Múltiplos Grupos: O objetivo desse tipo de estudo é a comparação entre todos os grupos ou conjuntos populacionais envolvidos no estudo. Ex: Análise Espacial. Desenhos de Séries Temporais: Avalia um determinado desfecho ao longo do tempo em uma determinada população geograficamente definida. Ex: Análise de Séries Temporais. Desenhos Mistos: É a combinação entre os dois desenhos citados, pois avalia a evolução de um determinado desfecho em diferentes grupos populacionais ao longo do tempo. Ex: Análise Espaço-Temporais, Estudos Multiníveis. 13.5 Aspectos históricos “Um estudo ecológico ou agregado focaliza a comparação de grupos, ao invés de indivíduos. A razão subjacente para este foco é que dados a nível individual da distribuição conjunta de duas (ou talvez todas) variáveis estão faltando internamente nos grupos; neste sentido um estudo ecológico é um desenho incompleto”. (Rothman, Kenneth J. et al. Modern epidemiology. Philadelphia: Wolters Kluwer Health/Lippincott Williams &amp; Wilkins, 2008.) “… estudar saúde no contexto ambiental. O objetivo é ambicioso: entender como o contexto afeta a saúde de pessoas e grupo através de seleção, distribuição, interação, adaptação, e outras respostas. Medidas de atributos do indivíduo não podem dar conta destes processos […] Sem medir estes contextos, nem padrão de mortalidade e morbidade, nem o espalhamento epidêmico, nem a transmissão sexual podem ser explicados” (Susser, Am.J.Public Health, 1994;84:825-835) A Epidemiologia é frequentemente definida em termos do estudo da determinação da distribuição da doença. Mas não se deve esquecer que quanto mais espalhada é uma causa particular, menos ela contribui para explicar a distribuição da doença.” “…dois tipos de perguntas etiológicas. A primeira busca as causas dos casos, e a segunda as causas da incidência.” “Aplicada à etiologia, a visão centralizada no indivíduo leva ao uso do risco-relativo como a representação básica da força etiológica: ou seja, o risco em indivíduos expostos relativo aos não-expostos. […] Esta pode ser geralmente a melhor medida de força etiológica, mas não é medida de […] importância em saúde pública.” “É rara a doença cuja taxa de incidência não tenha variado largamente, seja ao longo do tempo ou entre populações […] Isto significa que as causas da incidência, desconhecidas que sejam, não são inevitáveis. […] Mas identificar o agente causal pelos métodos tradicionais de caso-controle e coorte não terá sucesso se não houver suficientes diferenças na exposição dentro da população […] Nestas circunstâncias tudo os que os métodos tradicionais fazem é encontrar marcadores de susceptibilidade individual. A chave deve ser buscada nas diferenças entre populações ou em mudanças nas populações ao longo do tempo.” (Rose G. Sick individuals and sick populations. Int J Epidemiol. 2001 Jun;30(3):427-32; discussion 433-4.) “ … torna-se aparente que muitas das explicações convencionais dos determinantes da saúde - porque algumas pessoas são saudáveis e outras não - são, na melhor das hipóteses seriamente incompletas, se não simplesmente erradas. É assim, infelizmente, porque as sociedades modernas dedicam uma parte muito grande de sua riqueza, esforço e atenção tentando manter ou melhorar a saúde dos indivíduos que compõem suas populações. Estes esforços maciços são primeiramente canalizados para os sistemas de assistência à saúde, presumivelmente refletindo uma crença que receber uma boa assistência é o mais importante determinante de saúde.” (Evans,R.G.”Why are some people healthy and others not”) “Grande parte da pesquisa atual em epidemiologia está baseada no individualismo metodológico: a noção que a distribuição da saúde e doença em populações pode ser explicada exclusivamente em termos das características dos indivíduos.” (Diez-Roux AV. Bringing context back into epidemiology: variables and fallacies in multilevel analysis. AJPH,1998;88(2):216-22) “A evidência de modestos efeitos de vizinhança na saúde é razoavelmente consistente, apesar da heterogeneidade dos desenhos dos estudos […] e prováveis erros de medida. Ao chamar a atenção da saúde pública para os riscos associados com a estrutura social e ecológica de vizinhança, enseja-se possíveis intervenções inovadoras no nível da comunidade.” (Pickett KE, PearlL M. Multilevel analyses of neighbourhood socioeconomic context and health outcomes: a critical review. J Epidemiol Community Health 2001;55(2):111-22) 13.6 Epidemiologia social “…o ramo da epidemiologia que estuda a distribuição social e os determinantes sociais da saúde. A epidemiologia social incorpora um novo foco na comunidade como uma entidade em si, uma entidade mais complexa do que a soma das pessoas individuais que compõem a sociedade.” (Berkman L. F. &amp; Kawachi I. (Editors). Social Epidemiology. Oxford University Press, 2000) “Os médicos estão acostumados a pensar nos determinantes socioeconômicos da doença em termos dos fatores de risco de uma pessoa. […] Agora parece claro que a riqueza absoluta ou a renda é um determinante menos importante da saúde do que a relativa disparidade na renda ou a diferença de renda entre os ricos e os pobres.” (Kawachi I.; Kennedy B.P.; Wilkinson R.G. The Society and Population Health Reader: Income Inequality and Health. New Press, 1999). 13.7 Árvores, Bosques ou as Florestas? 13.7.1 As Árvores Suponha os dados abaixo, onde a variável “X” representa um efeito de exposição e a variável “Y” um taxa. Ao fazermos uma regressão obtemos uma correlação de apenas 0,1469 entre as duas variáveis. 13.7.2 Os Bosques Ao estratificarmos os dados evidencia-se uma estrutura, e ajustarmos uma regressão em cada grupo obtém-se: 13.7.3 As Florestas Tirando-se a média para cada grupo iremos obter quatro pontos sob os quais faremos uma regressão. O coeficiente de correlação obtido é rho = 0,9938 13.8 Falácia Ecológica ou viés de agregação “Viés que pode ocorrer porque uma associação entre duas variáveis no nível agregado não necessariamente representa uma associação no nível individual” O problema é que não podemos fazer inferências para níveis distintos: Inferir para o indivíduos a partir de dados agregados (falácia ecológica) Inferir para agregados populacionais a partir de dados individuais (falácia atomística ou individualista) Na estatística esse efeito é conhecido como Paradoxo de Simpson “Textos de Epidemiologia fazem uma avaliação consistente sobre estudos ecológicos: eles são tentativas cruas de estimar correlações em nível individual. […] Examinar esta questão de uma perspectiva diferente - como um problema geral de validade - mostrará que a falácia ecológica, conforme frequentemente usada, encoraja três noções interrelacionadas e falaciosas: que modelos em nível individual são mais perfeitamente especificados que os de nível ecológico, que correlações ecológicas são sempre substitutos para correlações de nível individual, e que variáveis de nível de grupo não causam doença.” (Schwartz, Am.J.Public Health, 1994;84:819-824) Religião e Sucídio Um exemplo clássico de estudo ecológico: Emile Durkheim (em 1897) associação ecológica positiva entre a proporção de indivíduos de religião Protestante e as taxas de suicídio (províncias da Prússia); Durkheim concluiu que Protestantes tinham maior probabilidade de se suicidarem do que os Católicos; Conclusão factível mas a inferência causal não é correta: poderiam ter sido os Católicos em províncias predominantemente Protestantes a cometer os suicídios, e a metodologia ecológica não permite discernir qual das duas hipóteses está certa. Para ler mais sobre este exemplo: Frans van Poppel and Lincoln H. Day. A Test of Durkheim’s Theory of Suicide - Without Committing the “Ecological Fallacy”. American Sociological Review, 1996. https://doi.org/10.2307/2096361 Posse de armas de fogo e suicídio Um exemplo mais recente: Miller et al (2003) realizaram um estudo ecológico no Estados Unidos comparando as frequências de posse doméstica de armas de fogo com as de suicídio por arma de fogo e por outros meios, por estado. Estados com maiores proporções de posse de armas de fogo apresentaram maiores taxas de suicídio por armas de fogo, mas a mesma frequência de suicídios por outros meios. Suicídios por outros meios serve como um “controle”. Segundo os autores, a posse de armas não deveria impactar suicídios por outros meios. Além disso, os autores assumem que os fatores de confundimento seriam os mesmos para suicídios por arma de fogo e por outros meios. Figura. Relação entre posse doméstica de armas de fogo e mortalidade por suicídio nos Estados Unidos, por estado, A) por armas de fogo, B) por outros meios que não armas de fogo, e C) todos. (Fonte: Miller et al. Am J Epidemiol. 2013;178(6):946–955) Concordam que todos os confundimentos são os mesmos para os dois grupos de mortes por suicídio? Concordam que suicídios por outros meios não devem ser afetados pela posse doméstica de armas de fogo? É correto concluir que, nos Estados Unidos: ter uma maior porcentagem de população com posse de armas causa taxas elevadas de suicídio por arma de fogo? possuir uma arma é uma causa para suicídio por arma de fogo? Um outro exemplo: Um pesquisador deseja estudar a relação entre acidentes de trânsito e a renda em três cidade distintas (A, B e C). pop renda_media tx_acidente A 24.08571 57.14 B 22.57143 42.86 C 21.41429 28.57 Observando o gráfico abaixo, o pesquisador observa um possível associaçãom entre a renda e a taxa de acidentes de trânsito; Quanto maior a renda, maior será a taxa de acidentes de trânsito. Observando os microdados, ou seja, os dados no nível individual, temos o seguinte: De posse desses dados no nível individual, é possível fazer a seguinte análise: Dessa forma observamos que os indivíduos que sofreram algum tipo de acidente de trânsito, apresentam a menor renda; Qual dos dois níveis de inferência está errado ? Qual é, então, o problema ? ? ? 13.9 Problemas práticos 1. Numerador: subregistro duplicidade de registros georreferenciamento: não localização informação incorreta preenchimento inadequado mudança na classificação ao longo do tempo 2. Denominador: espaçamento do censo migração mudança de fronteiras (!!!!) 3.Exposição: pode ocorrer em diversos lugares dificilmente mensurável com precisão uso de “proxy” diferentes áreas para medida de exposição e de efeito, e áreas não compatíveis Informações mais detalhadas (PNAD, amostra do censo) não extrapoláveis para populações pequenas 4. Análise: migração multicolinearidade 13.10 Vantagens Baixo custo e execução rápida, devido às fontes de dados secundários disponíveis; Conseguem estimar bem os efeitos de uma exposição quando ela varia pouco na área de estudo, pela comparação entre áreas (os estudos individuais não conseguem); Existem efeitos que somente podem ser medidos no nível ecológico, por ex. implantação de um novo sistema de saúde. 13.11 Desvantagens Informações sobre comportamento, atitudes e história clínica não estão disponíveis (dados pessoais não disponíveis); Depende da qualidade das informações disponíveis (fontes diversas); Não se leva em conta a variabilidade da característica estudada dentro do grupo; Difícil estabelecer temporalidade entre causa e efeito. Migração entre grupos (por exemplo, mora em uma área e trabalha em outra). 13.12 Resumindo Resgatando a ecologia: estudo das complexas inter-relações entre organismos vivos e o seu meio físico. Dados agregados – estudo ecológico clássico Mistura de dados individuais e agregados – modelos multinível Quando se estuda o tempo – séries temporais e modelos dinâmicos Quando é espacial – modelos clássicos de regressão ou espaciais Mistura espaço e tempo – modelos espaço-temporais Envolvendo relações entre indivíduos – redes 13.13 Exercícios Propostos As estatísticas internacionais indicam que o Chile tem uma das mais altas taxas de mortalidade por câncer de estômago. O país caracteriza-se por conter altos níveis de nitrato em seu solo, situação rara no mundo, neste particular. Estabeleceu-se a suspeita de ser o nitrato, em altas concentrações, um agente causal da neoplasia. Comparações regionais dentro do país, contrastando áreas com altas e baixas concentrações de nitrato, mostraram a mesma relação: alto teor da substância no solo, (alta mortalidade por este tipo de neoplasia). Um estudo caso-controle subseqüente foi realizado, mas a nível individual, não foi possível encontrar tal associação. A hipótese, entretanto, não foi totalmente descartada. Qual a importância desse estudo ecológico no estudo sobre causalidade: concentração de nitrato no solo vs câncer de estômago ? Os casos notificados de Influenza são maiores na cidade A do que na cidade B. As taxas de vacinação para a influenza são mais baixas na cidade A do que na cidade B. Quais das seguintes razões são razões pelas quais seria é incorreto presumir que uma maior vacinação na cidade B é o que está fazendo com que a cidade B tenha menos casos relatados de Influenza ? Escolha as opções corretas. A cidade A e a cidade B podem ter diferentes cepas de Influenza A cidade A e a cidade B podem ter proporções diferentes de pessoas nas suas populações que são especialmente vulneráveis à influenza (por exemplo, idosos, crianças e mulheres grávidas) A cidade A e a cidade B podem ter diferenças nos cuidados de saúde , acessibilidade aos serviços e acesso a diagnóstico da influenza A cidade A e a cidade B podem ter climas diferentes, levando a diferenças em como/onde as pessoas entram em contato com um ao outro. Isto pode afetar as taxas de transmissão de Influenza 13.14 Bibliografia sugerida BERKMAN, Lisa F.; KAWACHI, Ichirō; GLYMOUR, M. Maria (Ed.). Social epidemiology. Oxford University Press, 2014. DIEZ-ROUX, Ana V. Bringing context back into epidemiology: variables and fallacies in multilevel analysis. American journal of public health, v. 88, n. 2, p. 216-222, 1998. EVANS, Robert G.; BARER, Morris L.; MARMOR, Theodore R. (Ed.). Why are some people healthy and others not?: The determinants of the health of populations. Transaction Publishers, 1994. MORGENSTERN, Hal. Ecologic studies in epidemiology: concepts, principles, and methods. Annual review of public health, v. 16, n. 1, p. 61-81, 1995. PICKETT, Kate E.; PEARL, Michelle. Multilevel analyses of neighbourhood socioeconomic context and health outcomes: a critical review. Journal of Epidemiology &amp; Community Health, v. 55, n. 2, p. 111-122, 2001. ROSE, Geoffrey. Sick individuals and sick populations. International journal of epidemiology, v. 30, n. 3, p. 427-432, 2001. "],["introdução-às-séries-temporais-1.html", " 14 Introdução às Séries Temporais 14.1 O que são Séries Temporais ? 14.2 Hipóteses básicas do estudo das séries temporais 14.3 Classificação dos tipos de séries temporais 14.4 Processo Estocástico 14.5 Notação e Nomenclatura 14.6 Objetivos: análise de séries temporais 14.7 Estacionariedade 14.8 Pressuposto da Independência 14.9 Dependência serial 14.10 Função de Autocorrelação - FAC (Autocorrelation function - ACF) 14.11 Componentes de uma Série Temporal 14.12 Tendência 14.13 Sazonalidade 14.14 Ciclo 14.15 Termo Aleatório ou Ruído Branco 14.16 Composição dos Modelos de séries temporais 14.17 Decomposição de séries temporais 14.18 Prática no R 14.19 Exercícios Propostos 14.20 Outros materiais sobre Séries Temporais 14.21 Bibliografia sugerida", " 14 Introdução às Séries Temporais 14.1 O que são Séries Temporais ? Definição: Entende-se por Séries Temporais (ST) todo e qualquer conjunto de dados (absolutos ou relativos, discretos ou contínuos), ordenados cronologicamente. Condição: Esses dados seguem uma ordenação em função do tempo (dependência temporal). De modo geral, as séries temporais apresentam sequências de observações relativas a determinada variável ao longo de um intervalo específico de tempo (dia, mês, trimestre, ano, etc.), isto é, referem-se a fluxos de valores periódicos, os quais dão uma visão geral sobre o andamento ou comportamento da variável em análise. A maneira mais comum de visualizar séries temporais é usar um gráfico de linhas simples, em que o eixo horizontal representa os incrementos de tempo e o eixo vertical representa a variável que está sendo medida. Seguem abaixo alguns exemplo de séries temporais: As séries temporais podem ser de natureza regular ou irregular. As séries temporais regulares ou uniformes são aquelas que podem ser expressas sempre com o mesmo intervalo de tempo (frequência). As séries temporais irregulares ou não uniformes são aquelas em que as frequências de tempo são diferentes ou que apresentam dados ausentes (missing data). Algumas vezes podem ser transformadas em séries regulares agregando ouinterpolando os dados mensurados. 14.2 Hipóteses básicas do estudo das séries temporais Há um sistema causal relacionando as variáveis no tempo; Ao longo do tempo, o sistema influencia todos os dados sob análise, de modo regular e permanente; Os dados históricos refletem a influência média de um conjunto de fatores. Tais hipóteses se baseiam no pressuposto de que as relações apontadas pela experiência pregressa permitem prever o possível comportamento das variáveis sob análise, determinando se seu comportamento apresenta propriedades determinísticas e/ou aleatórias. 14.3 Classificação dos tipos de séries temporais Contínuas: A informação é obtida em qualquer intervalo de tempo (podendo ser discretizando em intervalos iguais) ou é acumulada por período. Ex: Temperatura, pluviosidade, partículas em suspensão. Discretas: Observações obtidas em intervalos de tempo discreto e equidistantes (ano, mês, dias, semanas epidemiológicas). Ex: Mortalidade infantil, notificações por DIC. Multivariada: São várias coleções de observações para a mesma sequência de períodos de tempo, ou seja,envolvem mais de uma série histórica. Ex: Número de homicídios e acidentes no Sudeste. Multidimensional: São várias coleções de observações para a mesma sequência de períodos de tempo, descrevendo o mesmo fenômeno em diferentes contextos. Ex: Número de AVCs em diversas UFs. 14.4 Processo Estocástico Um processo estocástico pode ser pensado de duas formas: um conjunto de possíveis trajetórias de um fenômeno físico que poderiam ser observadas; um conjunto de variáveis aleatórias, uma para cada tempo \\(t\\). Cada valor observado de uma trajetória é um dos possíveis valores que poderiam ter sido observados, de acordo com a distribuição de probabilidades da respectiva variável aleatória. Definir séries temporais consiste em determinar as funções matemáticas que apontam suas componentes básicas e permitem prever a evolução dos fenômenos estudados (como um eventual crescimento ou decrescimento futuro). As séries temporais podem ser matematicamente representadas por funções do tipo: \\[Z_t = f(tempo, a)\\] Sendo \\(Z_t\\) o valor da variável \\(Z\\) no tempo \\(t\\), e \\(a\\) a componente aleatória associada à função matemática do tempo. Série com a mesma estrutura: cada série é uma possível realização do mesmo processo estocástico. Trajetória ou série temporal ou função amostral 14.5 Notação e Nomenclatura Matematicamente, uma série temporal discreta é representada por: \\(Z_t = (Z_1 , Z_2 , Z_3 , ... , Z_n)\\), sendo: \\(Z\\), a variável observável e \\(t = 1,2,...,n\\), o parâmetro do tempo. Simulando duas séries temporais de um evento, com a mesma estrutura: 14.6 Objetivos: análise de séries temporais Objetivo Exemplo Descrição: verificar existência de tendência, sazonalidade, ciclos. Histogramas, boxplots, são ferramentas da análise exploratória descritiva Identificar tendência da AIDS; sazonalidade da dengue visando estabelecer melhor período de intervenção. Estabelecimento de causalidade: estudo da relação de causa-efeito Vacina X sarampo; Mortalidade por DIC X melhor assistência Classificação: identificação de padrões A série de leishmaniose tegumentar é “igual” à visceral? Controle: sistemas dinâmicos, caracterizados por uma entrada \\(X_t\\), uma série de saída \\(Z_t\\) e uma função de transferência \\(V_t\\) Modelar a resposta a medidas de controle de epidemia Monitoramento (nowcast): Detectar variações no comportamento da séries temporais conforme elas ocorram Dosagem de Hormônios ou de sinais vitais em CTI Predição (forecast) : prever o comportamento futuro de uma serie Predição de epidemias Atualização (nowcast): predição sobre o presente corrigir atraso de notificações 14.7 Estacionariedade Uma série temporal é dita estacionária quando ela se desenvolve no tempo aleatoriamente ao redor de uma média constante e com uma variância constante, refletindo alguma forma de equilíbrio estável. Na prática, a maioria das séries que encontramos apresentam algum tipo de não estacionariedade, como por exemplo, tendência. O modelo mais simples de uma séries temporal estacionária pode ser representado por: \\[Z_t = \\mu + a_t\\] Sendo \\(\\mu\\) a média do processo temporal e \\(a_t\\) a componente aleatória, chama de Ruído Branco em análises de séries temporais. A estacionariedade da séries temporais pode ser: 1\\(^a\\) ordem - média constante ao longo de todo o período 2\\(^a\\) ordem - variância constante ao longo de todo o período 14.7.1 Função de Autocovariância de um processo estacionário \\[\\gamma_h = E{\\{[Z_t - E(Z_t)][Z_{t-h} - E(Z_{t-h})]\\}}\\] A covariância não depende do tempo, mas da distância entre as observações. Um processo é considerado fracamente estacionário se: \\(E(Z_t)=\\mu\\), \\(\\forall t\\) (constante) \\(var(Z_t) = \\sigma^2\\), \\(\\forall t\\) (constante) \\(Cov(Z_t, Z_{t-h}) = \\gamma_h\\), \\(\\forall t\\) (não depende do instante no tempo, apenas da distância h) Sendo o ruído branco (White Noise), também chamado de Processo Puramente Randômico, uma variável aleatória \\(a_t\\), com média zero e variância \\(\\sigma²_a\\): \\(a_t \\sim N(0, \\sigma^2_a)\\) \\(Cov(a_t, a_{t-h}) = 0\\), \\(\\forall h \\neq 0\\) (Não correlacionados) 14.7.2 Por que a estacionariedade é importante ? A maioria das técnicas estatísticas utilizadas em séries temporais supõe que estas sejam estacionárias. Caso a série temporal não seja estacionária, será necessário transformar os dados. A transformação mais comum consiste em tomar diferenças sucessivas da série original, até se obter uma série estacionária. A primeira diferença de \\(Z_t\\): \\[\\bigtriangledown Z_t = Z_t - Z_{t-1}\\] A segunda diferença de \\(Z_t\\): \\[\\bigtriangledown^{2} Z_t = \\bigtriangledown[\\Delta Z_t] = \\bigtriangledown[Z_t - Z_{t-1}]\\] A n-ésima diferença de \\(Z_t\\): \\[\\bigtriangledown^{n} Z_t = \\bigtriangledown[\\bigtriangledown^{n-1} Z_t]\\] Logaritmo dos dados - Estabilizar a variância \\[\\bigtriangledown log Z_t = log Z_t - log Z_{t-1}\\] Transformações Box-Cox Pode-se diferenciar tantas vezes quanto necessário até estabilizar (porém, em geral se diferencia apenas uma vez, raramente duas vezes). Como saber se um processo é estacionário ? Visualizando a série, aplicando a decomposição, boxplots, etc. Testes Estatísticos, ex: Dickey-Fuller 14.8 Pressuposto da Independência Os métodos usuais de análise estatística de dados têm como pressuposto básico a independência dos eventos (casos). Ou seja, a ocorrência de um caso de doença em uma dada pessoa seria independente da ocorrência em outra pessoa. Pressupostos básicos para uma análise de regressão: \\(E(e_i) = 0\\) Variância \\(\\sigma^2\\) constante (homocedasticidade); \\(e_i \\sim N(0, \\sigma^2)\\) \\(e_i \\neq e_j\\), são independentes Na análise da incidência de doenças (ou qualquer outro indicador ecológico) ao longo do tempo isso não é verdade: a incidência em um determinado dia/mês ou ano em geral é correlacionada com a ocorrência no dia/mês/ano anterior. Esta correlação é expressa em uma função denominada função de autocorrelação. 14.9 Dependência serial Quanto à dependência, séries temporais podem possuir: Independência (sem dependência serial): série puramente aleatória ou ruído branco; Memória longa: a dependência desaparece lentamente (os valores de pontos no passado influenciam momentos muito adiante no tempo - exemplo: doenças com grande latência como hanseníase); Memória curta: dependência desaparece rapidamente (doenças de alta infecciosidade e “explosivas”\" - exemplo: influenza). 14.10 Função de Autocorrelação - FAC (Autocorrelation function - ACF) O coeficiente de correlação entre \\(Z_{t}\\) e \\(Z_{t-h}\\) é chamado de autocorrelação de h-ésima ordem e é denotadado por: \\[ {\\rho}_{k}=\\frac {Cov\\left({Z}_{t},{Z}_{t-h} \\right)}{\\sqrt{Var\\left({Z}_{t},{Z}_{t-h} \\right)}} =\\frac{Cov\\left({Z}_{t},{Z}_{t-h} \\right)}{Var\\left({Z}_{t} \\right)} =\\frac{{\\gamma}_{k}}{{\\gamma}_{0}} \\] Temos então: \\({\\rho}_{0}=1\\) \\(-1\\leq {\\rho}_{l} \\leq 1\\) Um conjunto de autocorrelações, \\(\\left\\{\\rho_{h}\\right\\}\\), é chamado de função de autocorrelação de \\(Z_{t}\\). Para uma dada amostra, \\(\\left\\{Z_{t}\\right\\}_{t=1}^{T}\\), suponha que \\(\\overline{Z}\\) é a média amostral. Então, a autocorrelação amostral de primeira ordem de \\(Z_{t}\\) pode ser definida como: \\[ {\\hat{\\rho}}_{1}=\\frac{\\sum _{t=2}^{T}{\\left({Z}_{t}-\\overline{Z}\\right) \\left({Z}_{t-1}-\\overline{Z}\\right)}}{\\sum_{t=1}^{T}{{\\left({Z}_{t}-\\overline{Z}\\right)}^{2}}} \\] que é um estimador consistente de \\({\\rho}_{1}\\). Em geral, a autocorrelação amostral de h-ésima ordem de \\(Z_{t}\\) pode ser definida como: \\[ {\\hat{\\rho}}_{h}=\\frac{\\sum_{t=h+1}^{T}{\\left({Z}_{t}-\\overline{Z}\\right) \\left({Z}_{t-h}-\\overline{Z} \\right)}}{\\sum_{t=1}^{T}{{\\left({Z}_{t}-\\overline{Z}\\right)}^{2}}} \\] para \\(0\\leq h \\leq T-1\\). Por exemplo, suponha que você está avaliando uma série temporal qualquer e quer visualizar como as defasagens da série podem impactar seu valor atual (ou seja, se \\(Z_{t}\\) é relacionado com \\(Z_{t-h}\\) para \\(k\\ge1\\)). A função de autocorrelação pode ser usada para obter tal informação. Num primeiro momento, visualize os dados da série para 10 lags (defasagens). Observe que os lags se tornam novas colunas e na medida que elas aumentam, incrementa-se as linhas sem observações. Apesar da simples correlação entre os dados nos ajudar a identificar defasagens que poderíam contribuir para o comportamento da série em \\(t\\), precisamos fazer uso de testes estatísticos que verifiquem a significância da relação entre o valor atual e suas lags. Neste sentido, a função de autocorrelação tem grande importância. Abaixo, um exemplo de função de autocorrelação. Observe que há duas linhas horizontais que representam os limites do teste de significância sendo que valores acima ou abaixo da linha são estatisticamente significantes. Neste documento, apresentaremos o teste que é realizado. O correlograma é uma das principais ferramentas de análise exploratória em séries temporais, pois indica como cada valor em um dado instante de tempo \\(t\\) se relaciona com os valores em \\(t+1, t+2,...,t+j\\) Para um dado \\(h\\), os resultados da Função de Autocorrelação podem ser testados usando um teste que pode ser representado pelas seguintes hipóteses: \\[ \\begin{aligned} &amp;&amp; H_{0}: \\rho_{h}=0 \\\\ &amp;&amp; H_{1}: \\rho_{h}\\neq 0 \\end{aligned} \\] 14.11 Componentes de uma Série Temporal As séries temporais podem ser separadas em componentes sistemáticas (apontam movimentos regulares) e não sistemáticas (apontam movimentos irregulares). São elas: Componentes Sistemáticas (podem ou não estar presentes) Tendência Sazonalidade Ciclo Componentes Não Sistemáticas Aleatória ou Ruído Branco As análises exploratórias de séries temporais buscam isolar e interpretar as componentes. Tais componentes podem atuar de maneira isolada ou inter-relacionadas. 14.12 Tendência É a indicadora da direção global dos dados (ou movimento geral da variável), do percurso traçado e de sua linha contínua; É o efeito de longo prazo na média. Pode ser o aumento ou redução a longo prazo… 14.13 Sazonalidade São ciclos de curto prazo (não maiores que um ano), em torno da tendência; Costumam se referir a eventos ligados a estação do ano, vinculados ao calendário e geralmente repetidos a cada doze meses; Efeitos ligados à variações periódicas (semanal, mensal, anual, etc.); Padrões que ocorrem em intervalos fixos. Ex: Medidas de Temperatura (aumenta no verão e diminui no inverno). 14.14 Ciclo Os ciclos são oscilações (aproximadamente regulares) em torno da tendência. Podem dever-se a fenômenos naturais, socioculturais ou econômicos, como variações climáticas (ex: excesso ou falta de chuva pode produzir ciclos agrícolas) Variações que apesar de periódicas não são associadas automaticamente a nenhuma medida do calendário; Aumento ou redução de frequência sem intervalos fixos. Ex: Ciclos Econômicos e Ciclos de epidemias. A diferença entre os ciclos, propriamente ditos, e a sazonalidade é o período de avaliação (curto e longo); A semelhança é que ambos definem oscilações relativamente regulares em torno da tendência. Na área de saúde é pouco comum encontrarmos ciclos, ainda que possam existir. 14.14.1 Como detectar a sazonalidade ? Visualmente Boxplots seasonplot monthplot decomposição 14.15 Termo Aleatório ou Ruído Branco Conceitualmente, a componente aleatória é uma mistura de pertubações bruscas, irregulares e esporádicas nos movimentos das séries que tipificam os fenômenos. Na realidade é resultante dos efeitos de múltiplas causas que dificilmente/não conseguem ser previstos. Exemplos típicos de eventos aleatórios: Secas Enchentes Terremotos Ocorrência de epidemias Crise política Conflitos Socioeconômicos 14.16 Composição dos Modelos de séries temporais A série pode ser descrita como sendo a soma ou multiplicação dos componentes (tendência, sazonalidade, ciclicidade - se houver - e termo aleatório). 14.16.1 Modelo Aditivo \\[Z_t = T_t + S_t + a_t\\] sendo \\(t = 1,2, ..., N\\) Essa composição de modelo sugere que a variação sazonal parece constante, não muda quando da série temporal aumenta. 14.16.2 Modelo Multiplicativo \\[Z_t = T_t . S_t . a_t\\] Essa composição de modelo sugere que a sazonalidade varia em conjunto com a tendência (aumenta de amplitude quando aumenta a tendência). Pode ser transformado em aditivo usando \\(log\\). \\[log(Z_t) = log(T_t . S_t . a_t) = log(T_t) + log(S_t) + log(a_t)\\] 14.17 Decomposição de séries temporais 14.18 Prática no R 14.18.1 A biblioteca ts é a mais utilizada no R Na biblioteca ts a função mais utilizada tem o mesmo nome ts , não é necessário chamar library(ts) pois a mesma já se encontra carregada por default. A função ts tem como argumentos principais: data: um vetor, data.frame ou matriz com dados para a série start: tempo da primeira observação e/ou end: tempo da última observação frequency: quantidade de observações por unidade de tempo, podendo representar: Anual = 1, Trimestral = 4, Mensal = 12 e Semanal = 52 14.18.2 Simulando uma Série Temporal Vamos simular uma série usando a função rnorm para gerar 60 pontos aleatórios , com media 0 e desvio 1 em seguida vamos usar a função ts para transformar o vetor em uma objeto ts e finalmente fazer um gráfico. # Uma serie temporal normalmente distribuída serie &lt;- rnorm(60) # usando a função ts para criar um objeto da classe ts # pode-se usar também end=c(2016,12) mas basta um! serie.ts &lt;- ts(serie,start = c(2012,1), frequency=12) Vamos observar agora como é um objeto do tipo ts serie.ts Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 2012 -0.850789274 1.098551160 -1.206355025 0.581862276 0.863689895 0.983052004 -1.271260251 -0.001062756 -0.960910158 1.259209306 -0.866606890 0.249044190 2013 -0.086168223 -0.492884341 -0.268998914 -0.399240236 -0.944297510 1.013188332 -0.408704068 -0.181086790 1.183755855 -1.608494491 -2.272439862 -2.040607916 2014 -0.648006354 0.717722237 -0.103400012 0.327017362 -0.977597331 0.341442983 0.043822392 -1.021578363 0.793427719 0.501624458 -1.554470354 0.883497837 2015 -0.207767801 1.831374014 0.177264382 -0.805840648 1.947932470 0.121197052 -0.354949127 1.052866250 1.163113962 -0.798832818 0.775455294 -1.995007352 2016 -0.350562193 0.380864742 0.258213780 0.964510263 -0.491278153 0.081638756 -0.161770723 1.272817069 -0.720269271 1.541051559 0.853661550 0.802399491 Para se obter o gráfico basta usar a função plot # gráfico da série plot(serie.ts) 14.18.3 Importando uma vetor e transformando em Série Temporal Vamos usar agora um exemplo de casos caxumba em Nova York de 1928-1972 proveniente do livro: Yorke, J.A. and London, W.P. (1973) “Recurrent Outbreaks of Measles, Chickenpox and Mumps”, American Journal of Epidemiology, Vol. 98, pp.469 Observe que a partir de um dado puramente vetorial já podemos obter um objeto ts Clique aqui para ver como são os dados brutos Para ler os dados utilizaremos a função scan que importa dados vetoriais. Nesse exemplo estaremos usando os dados diretos de uma URL mas o dado poderia estar no seu disco, assim você importaria localmente! OBSERVAÇÃO: No MS-Windows existe algum problema ao acessar sites seguros (HTTPS) assim vamos definir uma função que permita o acesso a esse tipo de site. podemos tentar duas coisas: options(url.method=&quot;libcurl&quot;) Ou criar uma função: scan.win &lt;- function(x) {scan(url(x,method = &#39;libcurl&#39;))} No Windows 10 aparentemente não é necessário o procedimento acima mas fique atento que ao longo do curso estaremos importando dados com frequência. Descubra como fazer essa importação funcionar no seu computador! Exemplo com dados de Caxumba, não se esqueça de definir a função acima! dados &lt;- scan(&#39;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/exemplos/caxumba.dat&#39;) caxumba &lt;- ts(dados,start = c(1928,1),frequency = 12) plot(caxumba) 14.18.4 Utilizando dados da incidência de dengue nas Filipinas, 2008 - 2016 Exemplo serie mensal da Incidência de dengue por 100,000hab em uma região das Filipinas de 2008 to 2016. Fonte: Kaggle dengue &lt;- read.csv(&quot;https://gitlab.procc.fiocruz.br/oswaldo/eco2019/raw/master/dados/denguecases2.csv&quot;) head(dengue) ## Month Year Dengue_Cases ## 1 Apr 2008 131.13331 ## 2 Aug 2008 159.97741 ## 3 Dec 2008 93.65630 ## 4 Feb 2008 49.38712 ## 5 Jan 2008 79.85915 ## 6 Jul 2008 152.63940 Antes de colocando em formato de série temporal utilizando a biblioteca ts do R, precisamos ordenar o dataframe para que possamos transformar corretamente em uma série temporal uma vez que a função baseia-se somente na ordem de entrada. Assim vamos alterar a coluna Month em um fator para que possamos manter a ordem dos meses e em seguida usar a função order para reordenar todo o dataframe. dengue$Month &lt;- factor(dengue$Month,levels = month.abb) dengue &lt;- dengue[order(dengue$Year,dengue$Month),] head(dengue) ## Month Year Dengue_Cases ## 5 Jan 2008 79.85915 ## 4 Feb 2008 49.38712 ## 8 Mar 2008 115.13416 ## 1 Apr 2008 131.13331 ## 9 May 2008 129.20466 ## 7 Jun 2008 210.24223 Com o dado na devida ordem e podemos continuar a transformação em série temporal. # Convertendo os dados para o formato de Séries Temporais # A frequency=12 foi especificado pois queremos mostrar dos dados mensais denguets &lt;- ts(dengue$Dengue_Cases,start=c(2008,1),frequency=12) plot(denguets, ylab=&quot;Casos de Dengue&quot;, xlab=&quot;Tempo&quot;) Verificando e testando a autocorrelação dos casos de dengue. \\[ \\begin{aligned} &amp;&amp; H_{0}: \\rho_{h}=0 \\\\ &amp;&amp; H_{1}: \\rho_{h}\\neq 0 \\end{aligned} \\] acf(denguets, lag.max=20, main=&quot;Função de Autocorrelação&quot;) Box.test(denguets, lag=20, type=&quot;Ljung-Box&quot;) Box-Ljung test data: denguets X-squared = 271.51, df = 20, p-value &lt; 2.2e-16 Através do gráfico e do teste do ACF, é possível verificar que a incidência de dengue é correlacionada ao longo do tempo. Fazendo uma análise descritiva da série temporal denguets Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 2008 79.85915 49.38712 115.13416 131.13331 129.20466 210.24223 152.63940 159.97741 307.65474 58.74152 36.17346 93.65630 2009 87.96879 96.47914 190.36630 98.15255 124.03703 215.76350 40.66555 39.54446 85.84889 70.55726 95.37771 171.74569 2010 81.62430 95.59756 174.13877 33.54686 32.44285 60.04658 55.22568 90.16454 135.63883 74.17619 71.39315 138.44613 2011 33.66412 46.52083 93.34766 58.76998 134.83900 187.12547 109.27259 88.23193 143.89752 53.87635 91.05780 184.88198 2012 114.48472 251.27249 400.20592 162.21779 191.47219 276.13014 75.88479 128.88087 423.70277 239.40052 421.72803 607.49949 2013 244.44260 374.95060 530.46735 75.91858 132.94225 678.00967 387.48040 448.67952 515.58071 303.43820 530.61714 696.56174 2014 56.28797 113.67882 522.16422 249.49254 326.64717 366.61897 237.79033 509.79051 469.48018 41.43502 87.44494 226.41755 2015 134.40762 255.93445 243.46980 212.50300 485.76066 331.08272 33.81837 60.95752 121.16441 104.00878 210.63816 160.61858 2016 201.73756 362.34941 270.55192 18.94775 57.02598 57.41445 70.58666 145.36292 116.41069 119.08265 245.19665 194.46347 Vamos verificar a propriedades da série: Estatística Função R Valor Comprimento da Serie length() 108 media mean() 192.0458131 mediana median() 134.62331 máximo max() 696.56174 minimo min() 18.947748 amplitude range() 18.947748, 696.56174 frequência frequency() 12 período de inicio start() 2008, 1 período de fim end() 2016, 12 Pode-se pedir também o sumário da série! summary(denguets) Min. 1st Qu. Median Mean 3rd Qu. Max. 18.95 81.18 134.62 192.05 246.27 696.56 hist(denguets,breaks = 10) boxplot(denguets,col=&#39;lightblue&#39;) Mudando a janela de tempo da série temporal: observando apenas os dados de Jan 2010 até Dez de 2012. denguets2 &lt;- window(denguets, start=c(2010,1),end=c(2012,12),frequency=12) plot(denguets2, ylab=&quot;Casos de Dengue&quot;, xlab=&quot;Tempo&quot;) Decompondo a série temporal Decompondo a série temporal dos casos de dengue via método clássico decompose (Decomposição via Médias Móveis): plot(decompose(denguets)) Decompondo a série temporal dos casos de dengue via STL (Seasonal and Trend decomposition using Loess): É mais robusta, mais sensível a vários tipos de sazonalidade e lida melhor com os outliers. plot(stl(denguets, s.window=&quot;periodic&quot;)) decom_dengue &lt;- stl(denguets,12) head(decom_dengue$time.series) seasonal trend remainder Jan 2008 -71.00930 132.7212 18.147256 Feb 2008 -26.81769 132.8553 -56.650467 Mar 2008 81.88596 132.9894 -99.741166 Apr 2008 -65.11369 133.1235 63.123548 May 2008 -22.99327 132.7289 19.468992 Jun 2008 80.32281 132.3344 -2.415003 plot(decom_dengue) Trend &lt;- decom_dengue$time.series[,2] Seasonal &lt;- decom_dengue$time.series[,1] Random &lt;- decom_dengue$time.series[,3] Refazendo o sinal original da séries temporais através das componentes: recomposed_dengue &lt;- Trend+Seasonal+Random par(mfrow=c(1,2)) plot(denguets, ylab=&quot;Incidência Dengue&quot;, main=&quot;Original&quot;) plot(as.ts(recomposed_dengue), ylab=&quot;Incidência Dengue&quot;, main=&quot;Recomposta&quot;) Em algumas séries temporais não é fácil avaliar suas componentes de maneira visual, ou seja, de maneira gráfica. Para podermos avaliar melhor precisamos utilizar alguns testes estatísticos. Outra forma de fazer gráficos é através das bibliotecas ggplot e ggfortify: library(ggplot2) library(ggfortify) autoplot(denguets) autoplot(decompose(denguets)) Avaliando a Estacionariedade da série temporal Segundo o teste de Dickey-Fuller: \\(H_{0}\\): A série temporal não é Estacionária \\(H_{1}\\): A série temporal é Estacionária Alguns exemplos: Testando a estacionariedade da série dos casos de dengue: library(tseries) adf.test(denguets) Augmented Dickey-Fuller Test data: denguets Dickey-Fuller = -1.9795, Lag order = 4, p-value = 0.5851 alternative hypothesis: stationary Como p-valor = 0,5851, não rejeitamos a hipótese nula, ou seja, não há indícios da série temporal ser estacionária. Avaliando a tendência em uma série temporal Construindo uma reta baseado no modelo de regressão linear simples para verificar a tendência da incidência da dengue: plot(denguets, main = &quot;Incidência de Dengue 2008 a 2016&quot;) abline(reg=lm(denguets ~ time(denguets)), col = &quot;red&quot;) Construindo uma curva suavizada baseada na função lowess para verificar tendência da incidência da dengue: plot(denguets, ylab=&quot;Casos de Dengue&quot;, xlab=&quot;Tempo&quot;) library(Kendall) lines(lowess(time(denguets),denguets),lwd=3, col=2) Uma outra forma de mostrar a tendência da série temporal é fazendo a média anual. Observe que a curva se parece um pouco com a curva do lowess porém menos suave. plot(aggregate(denguets, FUN=mean)) Avaliando a Sazonalidade da série temporal De maneira visual podemos utilizar algumas técnicas gráficas, tais como: Boxplot boxplot(denguets ~ cycle(denguets)) Monthplot monthplot(denguets) Seasonplot (funçao disponibilizada pela library forecast) library(forecast) seasonplot(denguets,col=terrain.colors(6),lwd=2) 14.19 Exercícios Propostos Utilizando os bancos: Série mensal de óbitos por doenças respiratórias na região Sul do Brasil de 1996 a 2017 (pode ser acessado na URL https://bit.ly/2P4CJj4, fonte: DataSUS/MS) Série semanal do numero de casos Malaria nos EUA de 1974 a 1984 (pode ser acessado na URL https://bit.ly/2KMXsCC, fonte:CDC/US) Importe a série para um formato ts e faça: Uma análise exploratórias dos dados em formato séries temporais; Decomponha a série temporal; Através de análises gráficas e/ou testes estatísticos, avalie e verifique a existência de tendência e sazonalidade na série. 14.20 Outros materiais sobre Séries Temporais Time Series Task View: https://cran.r-project.org/web/views/TimeSeries.html Blog, Ebook and Forecast Documentation by Rob Hyndman: https://otexts.org/fpp2/intro.html Extracting Seasonality and Trend from Data: Decomposition Using R https://anomaly.io/seasonal-trend-decomposition-in-r/index.html STL: A seasonal-trend decomposition procedure based on loess https://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/stl-a-seasonal-trend-decomposition-procedure-based-on-loess.pdf) Stackoverflow Community: https://stackoverflow.com/questions 14.21 Bibliografia sugerida DIGGLE, Peter. Time Series: A Biostatistical Introduction (Oxford Statistical Science Series, No. 5) 1st Edition, 1996 FERREIRA, Pedro Guilherme Costa. Análise de Séries Temporais em R: curso introdutório. 2018. METCALFE, Andrew V.; COWPERTWAIT, Paul SP. Introductory time series with R. Springer-Verlag New York, 2009. MORETTIN, Pedro A.; TOLOI, Clélia M.C. Análise de Séries Temporais: Modelos Lineares Univariados. Bluscher - ABE - Projeto Fisher. Edição 3, 2018. WOODWARD, Wayne A.; GRAY, Henry L.; ELLIOTT, Alan C. Applied time series analysis with R. CRC press, 2017. "]]
